{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP or Natural Language Processing is the art of making computers understand what is the meaning of natural language, we will accomplish this by using the NLTK or Natural Language ToolKit Library for python.\n",
    "NLP is the process of converting language into numbers that computer can understand. NLP can be used to understand text,\n",
    "speech, statements and many more.\n",
    "\n",
    "NLP has many advantages and can be used for various purposes, but the foremost beneficial use is for judjing the sentiments from the statements and the sentences in the language, and these kind of analysis can be beneficial for making other predictions and analysis in which the statements and sentences plays a major role.\n",
    "\n",
    "For ex. Prediciting which player we should select in our team for ipl based on the commentary.\n",
    "\n",
    "It has many more uses we will see as we move on in the tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing NLTK library\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now downloading all the dataset available in the nltk server using this command\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**What is TOKENIZING?**\n",
    "- TOKENIZING is a form of grouping things.\n",
    "  - Word Tokenizers(Group by words) \n",
    "  - Sentence Tokenizers(Group by sentences)\n",
    "- Token - Each \"entity\" that is a part of whatever was split up based on rules\n",
    "  - For examples, each word is a token when a sentence is \"tokenized\" into words. Each sentence can also be a token, if you tokenized the sentences out of a paragraph.\n",
    "  \n",
    "**What is CORPORA and LEXICON?**\n",
    "- Corpora is just a body of text ex. medical journal, presidential speeches, english languages\n",
    "- Lexicon can be thought of as a dictionary. Words and their meanings.\n",
    "  - But meaning varies with the reference.\n",
    "  - For ex. for investor bull means a person who is +ve about the market but in english it means a animal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Smith, how are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\"]\n",
      "['Hello', 'Mr.', 'Smith', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', ',', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'pinkish-blue', '.', 'You', 'should', \"n't\", 'eat', 'cardboard', '.']\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\"\n",
    "\n",
    "print(sent_tokenize(EXAMPLE_TEXT)) # Split on the basis of sentences and creates a list of the sentences.\n",
    "print(word_tokenize(EXAMPLE_TEXT)) # Split on the basis of word and creates a list of the words.\n",
    "# You can use a loop to access the elements in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words\n",
    "NLTK will not help us in giving meaningfull insight from the data instead it will help us in pre-processing the data, help us to make data suitable for appyling learning algorithms and it has many more features into it we will discover soon.\n",
    "\n",
    "The process of converting data to something a computer can understand is referred to as \"pre-processing.\" One of the major forms of pre-processing is going to be filtering out useless data. **In natural language processing, useless words (data), are referred to as stop words.**\n",
    "\n",
    "Immediately, we can recognize ourselves that some words carry more meaning than other words. We can also see that some words are just plain useless, and are filler words. We use them in the English language, for example, to sort of \"fluff\" up the sentence so it is not so strange sounding. An example of one of the most common, unofficial, useless words is the phrase \"umm.\" People stuff in \"umm\" frequently, some more than others. This word means nothing, unless of course we're searching for someone who is maybe lacking confidence, is confused, or hasn't practiced much speaking.\n",
    "\n",
    "**We would not want these words taking up space in our database, or taking up valuable processing time. As such, we call these words \"stop words\" because they are useless, and we wish to do nothing with them.** \n",
    "\n",
    "Another version of the term \"stop words\" can be more literal: Words we stop on. For example, you may wish to completely cease analysis if you detect words that are commonly used sarcastically, and stop immediately. Sarcastic words, or phrases are going to vary by lexicon and corpus. For now, we'll be considering stop words as words that just contain no meaning, and we want to remove them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whom', 'what', 'by', 'after', 'out', 'few', 'your', \"don't\", 'from', 'd', 'needn', 'very', \"aren't\", \"needn't\", 'aren', 'ourselves', 'when', \"mustn't\", 'to', 'mightn', 'for', 'once', \"couldn't\", 'more', 'on', \"shan't\", 'don', 'down', 'in', 'her', 'wasn', 'm', 'o', 'no', 'will', 'weren', 'won', \"won't\", 'll', 'same', 'being', \"hadn't\", 'couldn', 'so', \"mightn't\", 'should', 'against', 'is', 'herself', 'too', 'a', 'here', \"wouldn't\", \"she's\", 'we', 'i', 'but', \"doesn't\", 's', 'if', 'his', 'yourself', 'about', \"isn't\", 'through', 'didn', 'ours', 'or', 'until', 'himself', 'only', 'some', 'all', 'not', 'the', 'y', 'an', 'above', 'nor', 'been', 'does', \"you've\", 'me', 'their', \"you'd\", \"haven't\", \"you'll\", 'them', 'do', 'has', 'that', 'between', 'having', 'under', 'it', 'can', 'these', 'while', 't', 'wouldn', 'he', 'further', 'doesn', 'am', 'have', \"shouldn't\", 'itself', 'myself', 'again', 'ain', 'shan', 'shouldn', 'him', 'of', 'be', 'hadn', \"didn't\", 'themselves', 'she', 'its', 'my', \"that'll\", \"should've\", 'isn', 'who', 'our', 'were', 've', 'did', 'haven', \"weren't\", 'hers', 'just', 'there', 'off', 'own', 'they', 'below', 'as', \"you're\", 'now', \"wasn't\", 'other', 'ma', 'had', 'doing', 're', \"it's\", \"hasn't\", 'those', 'each', 'yourselves', 'mustn', 'why', 'most', 'yours', 'was', 'before', 'because', 'you', 'are', 'then', 'hasn', 'this', 'than', 'into', 'both', 'such', 'which', 'during', 'theirs', 'up', 'how', 'at', 'with', 'and', 'where', 'any', 'over'}\n"
     ]
    }
   ],
   "source": [
    "# Importing the stopword database or corpus from nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "# A Set is an unordered collection data type that is iterable, mutable, and has no duplicate elements.\n",
    "# Here we are creating a set of all english stopwords \n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "filtered_words = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_words.append(w)\n",
    "\n",
    "        \n",
    "print(filtered_words)\n",
    "\n",
    "# You can also do it like this -- another way just one line.\n",
    "fil_words = [w for w in word_tokens if w not in stop_words]\n",
    "print(fil_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming in NLTK\n",
    "\n",
    "**The idea of stemming is a sort of normalizing method. Many variations of words carry the same meaning, other than when tense is involved.**\n",
    "\n",
    "Consider:   \n",
    "I was taking a ride in the car.    \n",
    "I was riding in the car.\n",
    "\n",
    "This sentence means the same thing. in the car is the same. I was is the same. the ing denotes a clear past-tense in both cases, so is it truly necessary to differentiate between ride and riding, in the case of just trying to figure out the meaning of what this past-tense activity was?\n",
    "\n",
    "No, not really.\n",
    "\n",
    "Having individual dictionary entries per version would be highly redundant and inefficient, especially since, once we convert to numbers, the \"value\" is going to be identical.  \n",
    "One of the most popular stemming algorithms is the Porter stemmer, which has been around since 1979.  \n",
    "\n",
    "\n",
    "**Stemming is the process of reducing a word into its stem, i.e. its root form. The root form is not necessarily a word by itself, but it can be used to generate words by concatenating the right suffix.**  \n",
    "\n",
    "**For example, the words fish, fishes and fishing all stem into fish, which is a correct word. On the other side, the words study, studies and studying stems into studi, which is not an English word.**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Porter Stemmer from nltk.stem module\n",
    "from nltk.stem import PorterStemmer\n",
    "Ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n",
    "\n",
    "for words in example_words:\n",
    "    print(Ps.stem(words))\n",
    "# This will print the root word in the words.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "is\n",
      "import\n",
      "to\n",
      "by\n",
      "veri\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "poorli\n",
      "at\n",
      "least\n",
      "onc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "new_text = \"It is important to by very pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\"\n",
    "words = word_tokenize(new_text)\n",
    "\n",
    "for word in words:\n",
    "    print(Ps.stem(word))\n",
    "    \n",
    "# Why we are doing Stemming?  Answer is that we have different variations of the same word but the meaning is unchanged.\n",
    "# so why we give the same word different number score if they have the same meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-Of-Speech (POS) Tagging\n",
    "**It means labeling words in a sentence as nouns, adjectives, verbs...etc. Even more impressive, it also labels by tense, and more.**\n",
    "\n",
    "Part-of-speech (POS) tagging is the process of assigning a word to its grammatical category, in order to understand its role within the sentence. Traditional parts of speech are nouns, verbs, adverbs, conjunctions, etc.\n",
    "\n",
    "**Part-of-speech taggers typically take a sequence of words (i.e. a sentence) as input, and provide a list of tuples as output, where each word is associated with the related tag.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tag list:\n",
    "\n",
    "CC\tcoordinating conjunction\n",
    "CD\tcardinal digit\n",
    "DT\tdeterminer\n",
    "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "FW\tforeign word\n",
    "IN\tpreposition/subordinating conjunction\n",
    "JJ\tadjective\t'big'\n",
    "JJR\tadjective, comparative\t'bigger'\n",
    "JJS\tadjective, superlative\t'biggest'\n",
    "LS\tlist marker\t1)\n",
    "MD\tmodal\tcould, will\n",
    "NN\tnoun, singular 'desk'\n",
    "NNS\tnoun plural\t'desks'\n",
    "NNP\tproper noun, singular\t'Harrison'\n",
    "NNPS\tproper noun, plural\t'Americans'\n",
    "PDT\tpredeterminer\t'all the kids'\n",
    "POS\tpossessive ending\tparent's\n",
    "PRP\tpersonal pronoun\tI, he, she\n",
    "PRP$\tpossessive pronoun\tmy, his, hers\n",
    "RB\tadverb\tvery, silently,\n",
    "RBR\tadverb, comparative\tbetter\n",
    "RBS\tadverb, superlative\tbest\n",
    "RP\tparticle\tgive up\n",
    "TO\tto\tgo 'to' the store.\n",
    "UH\tinterjection\terrrrrrrrm\n",
    "VB\tverb, base form\ttake\n",
    "VBD\tverb, past tense\ttook\n",
    "VBG\tverb, gerund/present participle\ttaking\n",
    "VBN\tverb, past participle\ttaken\n",
    "VBP\tverb, sing. present, non-3d\ttake\n",
    "VBZ\tverb, 3rd person sing. present\ttakes\n",
    "WDT\twh-determiner\twhich\n",
    "WP\twh-pronoun\twho, what\n",
    "WP$\tpossessive wh-pronoun\twhose\n",
    "WRB\twh-abverb\twhere, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the texts of the State of the Union addresses, using the state_union corpus reader. \n",
    "# Count occurrences of men, women, and people in each document. \n",
    "from nltk.corpus import state_union\n",
    "# This tokenizer is based on unsupervised learning algorithm and it comes pretrained but you can also train it.\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "February 2, 2005\n",
      "\n",
      "\n",
      "9:10 P.M. EST \n",
      "\n",
      "THE PRESIDENT: Mr. Speaker, Vice President Cheney, members of Congress, fellow citizens: \n",
      "\n",
      "As a new Congress gathers, all of us in the elected branches of government share a great privilege: We've been placed in office by the votes of the people we serve. And tonight that is a privilege we share with newly-elected leaders of Afghanistan, the Palestinian Territories, Ukraine, and a free and sovereign Iraq. (Applause.) \n",
      "\n",
      "Two weeks ago, I stood on the steps of this Capitol and renewed the commitment of our nation to the guiding ideal of liberty for all. This evening I will set forth policies to advance that ideal at home and around the world. \n",
      "\n",
      "Tonight, with a healthy, growing economy, with more Americans going back to work, with our nation an active force for good in the world -- the state of our union is confident and strong. (Applause.) \n",
      "\n",
      "Our generation has been blessed -- by the expansion of opportunity, by advances in medicine, by the security purchased by our parents' sacrifice. Now, as we see a little gray in the mirror -- or a lot of gray -- (laughter) -- and we watch our children moving into adulthood, we ask the question: What will be the state of their union? Members of Congress, the choices we make together will answer that question. Over the next several months, on issue after issue, let us do what Americans have always done, and build a better world for our children and our grandchildren. (Applause.) \n",
      "\n",
      "First, we must be good stewards of this economy, and renew the great institutions on which millions of our fellow citizens rely. America's economy is the fastest growing of any major industrialized nation. In the past four years, we provided tax relief to every person who pays income taxes, overcome a recession, opened up new markets abroad, prosecuted corporate criminals, raised homeownership to its highest level in history, and in the last year alone, the United States has added 2.3 million new jobs. (Applause.) When action was needed, the Congress delivered -- and the nation is grateful. \n",
      "\n",
      "Now we must add to these achievements. By making our economy more flexible, more innovative, and more competitive, we will keep America the economic leader of the world. (Applause.) \n",
      "\n",
      "America's prosperity requires restraining the spending appetite of the federal government. I welcome the bipartisan enthusiasm for spending discipline. I will send you a budget that holds the growth of discretionary spending below inflation, makes tax relief permanent, and stays on track to cut the deficit in half by 2009. (Applause.) My budget substantially reduces or eliminates more than 150 government programs that are not getting results, or duplicate current efforts, or do not fulfill essential priorities. The principle here is clear: Taxpayer dollars must be spent wisely, or not at all. (Applause.) \n",
      "\n",
      "To make our economy stronger and more dynamic, we must prepare a rising generation to fill the jobs of the 21st century. Under the No Child Left Behind Act, standards are higher, test scores are on the rise, and we're closing the achievement gap for minority students. Now we must demand better results from our high schools, so every high school diploma is a ticket to success. We will help an additional 200,000 workers to get training for a better career, by reforming our job training system and strengthening America's community colleges. And we'll make it easier for Americans to afford a college education, by increasing the size of Pell Grants. (Applause.) \n",
      "\n",
      "To make our economy stronger and more competitive, America must reward, not punish, the efforts and dreams of entrepreneurs. Small business is the path of advancement, especially for women and minorities, so we must free small businesses from needless regulation and protect honest job-creators from junk lawsuits. (Applause.) Justice is distorted, and our economy is held back by irresponsible class-actions and frivolous asbestos claims -- and I urge Congress to pass legal reforms this year. (Applause.) \n",
      "\n",
      "To make our economy stronger and more productive, we must make health care more affordable, and give families greater access to good coverage -- (applause) -- and more control over their health decisions. (Applause.) I ask Congress to move forward on a comprehensive health care agenda with tax credits to help low-income workers buy insurance, a community health center in every poor country, improved information technology to prevent medical error and needless costs, association health plans for small businesses and their employees -- (applause) -- expanded health savings accounts -- (applause) -- and medical liability reform that will reduce health care costs and make sure patients have the doctors and care they need. (Applause.) \n",
      "\n",
      "To keep our economy growing, we also need reliable supplies of affordable, environmentally responsible energy. (Applause.) Nearly four years ago, I submitted a comprehensive energy strategy that encourages conservation, alternative sources, a modernized electricity grid, and more production here at home -- including safe, clean nuclear energy. (Applause.) My Clear Skies legislation will cut power plant pollution and improve the health of our citizens. (Applause.) And my budget provides strong funding for leading-edge technology -- from hydrogen-fueled cars, to clean coal, to renewable sources such as ethanol. (Applause.) Four years of debate is enough: I urge Congress to pass legislation that makes America more secure and less dependent on foreign energy. (Applause.) \n",
      "\n",
      "All these proposals are essential to expand this economy and add new jobs -- but they are just the beginning of our duty. To build the prosperity of future generations, we must update institutions that were created to meet the needs of an earlier time. Year after year, Americans are burdened by an archaic, incoherent federal tax code. I've appointed a bipartisan panel to examine the tax code from top to bottom. And when their recommendations are delivered, you and I will work together to give this nation a tax code that is pro-growth, easy to understand, and fair to all. (Applause.) \n",
      "\n",
      "America's immigration system is also outdated -- unsuited to the needs of our economy and to the values of our country. We should not be content with laws that punish hardworking people who want only to provide for their families, and deny businesses willing workers, and invite chaos at our border. It is time for an immigration policy that permits temporary guest workers to fill jobs Americans will not take, that rejects amnesty, that tells us who is entering and leaving our country, and that closes the border to drug dealers and terrorists. (Applause.) \n",
      "\n",
      "One of America's most important institutions -- a symbol of the trust between generations -- is also in need of wise and effective reform. Social Security was a great moral success of the 20th century, and we must honor its great purposes in this new century. (Applause.) The system, however, on its current path, is headed toward bankruptcy. And so we must join together to strengthen and save Social Security. (Applause.) \n",
      "\n",
      "Today, more than 45 million Americans receive Social Security benefits, and millions more are nearing retirement -- and for them the system is sound and fiscally strong. I have a message for every American who is 55 or older: Do not let anyone mislead you; for you, the Social Security system will not change in any way. (Applause.) For younger workers, the Social Security system has serious problems that will grow worse with time. Social Security was created decades ago, for a very different era. In those days, people did not live as long. Benefits were much lower than they are today. And a half-century ago, about sixteen workers paid into the system for each person drawing benefits. \n",
      "\n",
      "Our society has changed in ways the founders of Social Security could not have foreseen. In today's world, people are living longer and, therefore, drawing benefits longer. And those benefits are scheduled to rise dramatically over the next few decades. And instead of sixteen workers paying in for every beneficiary, right now it's only about three workers. And over the next few decades that number will fall to just two workers per beneficiary. With each passing year, fewer workers are paying ever-higher benefits to an ever-larger number of retirees. \n",
      "\n",
      "So here is the result: Thirteen years from now, in 2018, Social Security will be paying out more than it takes in. And every year afterward will bring a new shortfall, bigger than the year before. For example, in the year 2027, the government will somehow have to come up with an extra $200 billion to keep the system afloat -- and by 2033, the annual shortfall would be more than $300 billion. By the year 2042, the entire system would be exhausted and bankrupt. If steps are not taken to avert that outcome, the only solutions would be dramatically higher taxes, massive new borrowing, or sudden and severe cuts in Social Security benefits or other government programs. \n",
      "\n",
      "I recognize that 2018 and 2042 may seem a long way off. But those dates are not so distant, as any parent will tell you. If you have a five-year-old, you're already concerned about how you'll pay for college tuition 13 years down the road. If you've got children in their 20s, as some of us do, the idea of Social Security collapsing before they retire does not seem like a small matter. And it should not be a small matter to the United States Congress. (Applause.) You and I share a responsibility. We must pass reforms that solve the financial problems of Social Security once and for all. \n",
      "\n",
      "Fixing Social Security permanently will require an open, candid review of the options. Some have suggested limiting benefits for wealthy retirees. Former Congressman Tim Penny has raised the possibility of indexing benefits to prices rather than wages. During the 1990s, my predecessor, President Clinton, spoke of increasing the retirement age. Former Senator John Breaux suggested discouraging early collection of Social Security benefits. The late Senator Daniel Patrick Moynihan recommended changing the way benefits are calculated. All these ideas are on the table. \n",
      "\n",
      "I know that none of these reforms would be easy. But we have to move ahead with courage and honesty, because our children's retirement security is more important than partisan politics. (Applause.) I will work with members of Congress to find the most effective combination of reforms. I will listen to anyone who has a good idea to offer. (Applause.) We must, however, be guided by some basic principles. We must make Social Security permanently sound, not leave that task for another day. We must not jeopardize our economic strength by increasing payroll taxes. We must ensure that lower-income Americans get the help they need to have dignity and peace of mind in their retirement. We must guarantee there is no change for those now retired or nearing retirement. And we must take care that any changes in the system are gradual, so younger workers have years to prepare and plan for their future. \n",
      "\n",
      "As we fix Social Security, we also have the responsibility to make the system a better deal for younger workers. And the best way to reach that goal is through voluntary personal retirement accounts. (Applause.) Here is how the idea works. Right now, a set portion of the money you earn is taken out of your paycheck to pay for the Social Security benefits of today's retirees. If you're a younger worker, I believe you should be able to set aside part of that money in your own retirement account, so you can build a nest egg for your own future. \n",
      "\n",
      "Here's why the personal accounts are a better deal. Your money will grow, over time, at a greater rate than anything the current system can deliver -- and your account will provide money for retirement over and above the check you will receive from Social Security. In addition, you'll be able to pass along the money that accumulates in your personal account, if you wish, to your children and -- or grandchildren. And best of all, the money in the account is yours, and the government can never take it away. (Applause.) \n",
      "\n",
      "The goal here is greater security in retirement, so we will set careful guidelines for personal accounts. We'll make sure the money can only go into a conservative mix of bonds and stock funds. We'll make sure that your earnings are not eaten up by hidden Wall Street fees. We'll make sure there are good options to protect your investments from sudden market swings on the eve of your retirement. We'll make sure a personal account cannot be emptied out all at once, but rather paid out over time, as an addition to traditional Social Security benefits. And we'll make sure this plan is fiscally responsible, by starting personal retirement accounts gradually, and raising the yearly limits on contributions over time, eventually permitting all workers to set aside four percentage points of their payroll taxes in their accounts. \n",
      "\n",
      "Personal retirement accounts should be familiar to federal employees, because you already have something similar, called the Thrift Savings Plan, which lets workers deposit a portion of their paychecks into any of five different broadly-based investment funds. It's time to extend the same security, and choice, and ownership to young Americans. (Applause.) \n",
      "\n",
      "Our second great responsibility to our children and grandchildren is to honor and to pass along the values that sustain a free society. So many of my generation, after a long journey, have come home to family and faith, and are determined to bring up responsible, moral children. Government is not the source of these values, but government should never undermine them. \n",
      "\n",
      "Because marriage is a sacred institution and the foundation of society, it should not be re-defined by activist judges. For the good of families, children, and society, I support a constitutional amendment to protect the institution of marriage. (Applause.) \n",
      "\n",
      "Because a society is measured by how it treats the weak and vulnerable, we must strive to build a culture of life. Medical research can help us reach that goal, by developing treatments and cures that save lives and help people overcome disabilities -- and I thank the Congress for doubling the funding of the National Institutes of Health. (Applause.) To build a culture of life, we must also ensure that scientific advances always serve human dignity, not take advantage of some lives for the benefit of others. We should all be able to agree -- (applause) -- we should all be able to agree on some clear standards. I will work with Congress to ensure that human embryos are not created for experimentation or grown for body parts, and that human life is never bought and sold as a commodity. (Applause.) America will continue to lead the world in medical research that is ambitious, aggressive, and always ethical. \n",
      "\n",
      "Because courts must always deliver impartial justice, judges have a duty to faithfully interpret the law, not legislate from the bench. (Applause.) As President, I have a constitutional responsibility to nominate men and women who understand the role of courts in our democracy, and are well-qualified to serve on the bench -- and I have done so. (Applause.) The Constitution also gives the Senate a responsibility: Every judicial nominee deserves an up or down vote. (Applause.) \n",
      "\n",
      "Because one of the deepest values of our country is compassion, we must never turn away from any citizen who feels isolated from the opportunities of America. Our government will continue to support faith-based and community groups that bring hope to harsh places. Now we need to focus on giving young people, especially young men in our cities, better options than apathy, or gangs, or jail. Tonight I propose a three-year initiative to help organizations keep young people out of gangs, and show young men an ideal of manhood that respects women and rejects violence. (Applause.) Taking on gang life will be one part of a broader outreach to at-risk youth, which involves parents and pastors, coaches and community leaders, in programs ranging from literacy to sports. And I am proud that the leader of this nationwide effort will be our First Lady, Laura Bush. (Applause.) \n",
      "\n",
      "Because HIV/AIDS brings suffering and fear into so many lives, I ask you to reauthorize the Ryan White Act to encourage prevention, and provide care and treatment to the victims of that disease. (Applause.) And as we update this important law, we must focus our efforts on fellow citizens with the highest rates of new cases, African American men and women. (Applause.) \n",
      "\n",
      "Because one of the main sources of our national unity is our belief in equal justice, we need to make sure Americans of all races and backgrounds have confidence in the system that provides justice. In America we must make doubly sure no person is held to account for a crime he or she did not commit -- so we are dramatically expanding the use of DNA evidence to prevent wrongful conviction. (Applause.) Soon I will send to Congress a proposal to fund special training for defense counsel in capital cases, because people on trial for their lives must have competent lawyers by their side. (Applause.) \n",
      "\n",
      "Our third responsibility to future generations is to leave them an America that is safe from danger, and protected by peace. We will pass along to our children all the freedoms we enjoy -- and chief among them is freedom from fear. \n",
      "\n",
      "In the three and a half years since September the 11th, 2001, we have taken unprecedented actions to protect Americans. We've created a new department of government to defend our homeland, focused the FBI on preventing terrorism, begun to reform our intelligence agencies, broken up terror cells across the country, expanded research on defenses against biological and chemical attack, improved border security, and trained more than a half-million first responders. Police and firefighters, air marshals, researchers, and so many others are working every day to make our homeland safer, and we thank them all. (Applause.) \n",
      "\n",
      "Our nation, working with allies and friends, has also confronted the enemy abroad, with measures that are determined, successful, and continuing. The al Qaeda terror network that attacked our country still has leaders -- but many of its top commanders have been removed. There are still governments that sponsor and harbor terrorists -- but their number has declined. There are still regimes seeking weapons of mass destruction -- but no longer without attention and without consequence. Our country is still the target of terrorists who want to kill many, and intimidate us all -- and we will stay on the offensive against them, until the fight is won. (Applause.) \n",
      "\n",
      "Pursuing our enemies is a vital commitment of the war on terror -- and I thank the Congress for providing our servicemen and women with the resources they have needed. During this time of war, we must continue to support our military and give them the tools for victory. (Applause.) \n",
      "\n",
      "Other nations around the globe have stood with us. In Afghanistan, an international force is helping provide security. In Iraq, 28 countries have troops on the ground, the United Nations and the European Union provided technical assistance for the elections, and NATO is leading a mission to help train Iraqi officers. We're cooperating with 60 governments in the Proliferation Security Initiative, to detect and stop the transit of dangerous materials. We're working closely with the governments in Asia to convince North Korea to abandon its nuclear ambitions. Pakistan, Saudi Arabia, and nine other countries have captured or detained al Qaeda terrorists. In the next four years, my administration will continue to build the coalitions that will defeat the dangers of our time. (Applause.) \n",
      "\n",
      "In the long-term, the peace we seek will only be achieved by eliminating the conditions that feed radicalism and ideologies of murder. If whole regions of the world remain in despair and grow in hatred, they will be the recruiting grounds for terror, and that terror will stalk America and other free nations for decades. The only force powerful enough to stop the rise of tyranny and terror, and replace hatred with hope, is the force of human freedom. (Applause.) Our enemies know this, and that is why the terrorist Zarqawi recently declared war on what he called the \"evil principle\" of democracy. And we've declared our own intention: America will stand with the allies of freedom to support democratic movements in the Middle East and beyond, with the ultimate goal of ending tyranny in our world. (Applause.) \n",
      "\n",
      "The United States has no right, no desire, and no intention to impose our form of government on anyone else. That is one of the main differences between us and our enemies. They seek to impose and expand an empire of oppression, in which a tiny group of brutal, self-appointed rulers control every aspect of every life. Our aim is to build and preserve a community of free and independent nations, with governments that answer to their citizens, and reflect their own cultures. And because democracies respect their own people and their neighbors, the advance of freedom will lead to peace. (Applause.) \n",
      "\n",
      "That advance has great momentum in our time -- shown by women voting in Afghanistan, and Palestinians choosing a new direction, and the people of Ukraine asserting their democratic rights and electing a president. We are witnessing landmark events in the history of liberty. And in the coming years, we will add to that story. (Applause.) \n",
      "\n",
      "The beginnings of reform and democracy in the Palestinian territories are now showing the power of freedom to break old patterns of violence and failure. Tomorrow morning, Secretary of State Rice departs on a trip that will take her to Israel and the West Bank for meetings with Prime Minister Sharon and President Abbas. She will discuss with them how we and our friends can help the Palestinian people end terror and build the institutions of a peaceful, independent, democratic state. To promote this democracy, I will ask Congress for $350 million to support Palestinian political, economic, and security reforms. The goal of two democratic states, Israel and Palestine, living side by side in peace, is within reach -- and America will help them achieve that goal. (Applause.) \n",
      "\n",
      "To promote peace and stability in the broader Middle East, the United States will work with our friends in the region to fight the common threat of terror, while we encourage a higher standard of freedom. Hopeful reform is already taking hold in an arc from Morocco to Jordan to Bahrain. The government of Saudi Arabia can demonstrate its leadership in the region by expanding the role of its people in determining their future. And the great and proud nation of Egypt, which showed the way toward peace in the Middle East, can now show the way toward democracy in the Middle East. (Applause.) \n",
      "\n",
      "To promote peace in the broader Middle East, we must confront regimes that continue to harbor terrorists and pursue weapons of mass murder. Syria still allows its territory, and parts of Lebanon, to be used by terrorists who seek to destroy every chance of peace in the region. You have passed, and we are applying, the Syrian Accountability Act -- and we expect the Syrian government to end all support for terror and open the door to freedom. (Applause.) Today, Iran remains the world's primary state sponsor of terror -- pursuing nuclear weapons while depriving its people of the freedom they seek and deserve. We are working with European allies to make clear to the Iranian regime that it must give up its uranium enrichment program and any plutonium reprocessing, and end its support for terror. And to the Iranian people, I say tonight: As you stand for your own liberty, America stands with you. (Applause.) \n",
      "\n",
      "Our generational commitment to the advance of freedom, especially in the Middle East, is now being tested and honored in Iraq. That country is a vital front in the war on terror, which is why the terrorists have chosen to make a stand there. Our men and women in uniform are fighting terrorists in Iraq, so we do not have to face them here at home. (Applause.) And the victory of freedom in Iraq will strengthen a new ally in the war on terror, inspire democratic reformers from Damascus to Tehran, bring more hope and progress to a troubled region, and thereby lift a terrible threat from the lives of our children and grandchildren. \n",
      "\n",
      "We will succeed because the Iraqi people value their own liberty -- as they showed the world last Sunday. (Applause.) Across Iraq, often at great risk, millions of citizens went to the polls and elected 275 men and women to represent them in a new Transitional National Assembly. A young woman in Baghdad told of waking to the sound of mortar fire on election day, and wondering if it might be too dangerous to vote. She said, \"Hearing those explosions, it occurred to me -- the insurgents are weak, they are afraid of democracy, they are losing. So I got my husband, and I got my parents, and we all came out and voted together.\" \n",
      "\n",
      "Americans recognize that spirit of liberty, because we share it. In any nation, casting your vote is an act of civic responsibility; for millions of Iraqis, it was also an act of personal courage, and they have earned the respect of us all. (Applause.) \n",
      "\n",
      "One of Iraq's leading democracy and human rights advocates is Safia Taleb al-Suhail. She says of her country, \"We were occupied for 35 years by Saddam Hussein. That was the real occupation. Thank you to the American people who paid the cost, but most of all, to the soldiers.\" Eleven years ago, Safia's father was assassinated by Saddam's intelligence service. Three days ago in Baghdad, Safia was finally able to vote for the leaders of her country -- and we are honored that she is with us tonight. (Applause.) \n",
      "\n",
      "The terrorists and insurgents are violently opposed to democracy, and will continue to attack it. Yet, the terrorists' most powerful myth is being destroyed. The whole world is seeing that the car bombers and assassins are not only fighting coalition forces, they are trying to destroy the hopes of Iraqis, expressed in free elections. And the whole world now knows that a small group of extremists will not overturn the will of the Iraqi people. (Applause.) \n",
      "\n",
      "We will succeed in Iraq because Iraqis are determined to fight for their own freedom, and to write their own history. As Prime Minister Allawi said in his speech to Congress last September, \"Ordinary Iraqis are anxious to shoulder all the security burdens of our country as quickly as possible.\" That is the natural desire of an independent nation, and it is also the stated mission of our coalition in Iraq. The new political situation in Iraq opens a new phase of our work in that country. \n",
      "\n",
      "At the recommendation of our commanders on the ground, and in consultation with the Iraqi government, we will increasingly focus our efforts on helping prepare more capable Iraqi security forces -- forces with skilled officers and an effective command structure. As those forces become more self-reliant and take on greater security responsibilities, America and its coalition partners will increasingly be in a supporting role. In the end, Iraqis must be able to defend their own country -- and we will help that proud, new nation secure its liberty. \n",
      "\n",
      "Recently an Iraqi interpreter said to a reporter, \"Tell America not to abandon us.\" He and all Iraqis can be certain: While our military strategy is adapting to circumstances, our commitment remains firm and unchanging. We are standing for the freedom of our Iraqi friends, and freedom in Iraq will make America safer for generations to come. (Applause.) We will not set an artificial timetable for leaving Iraq, because that would embolden the terrorists and make them believe they can wait us out. We are in Iraq to achieve a result: A country that is democratic, representative of all its people, at peace with its neighbors, and able to defend itself. And when that result is achieved, our men and women serving in Iraq will return home with the honor they have earned. (Applause.) \n",
      "\n",
      "Right now, Americans in uniform are serving at posts across the world, often taking great risks on my orders. We have given them training and equipment; and they have given us an example of idealism and character that makes every American proud. (Applause.) The volunteers of our military are unrelenting in battle, unwavering in loyalty, unmatched in honor and decency, and every day they're making our nation more secure. Some of our servicemen and women have survived terrible injuries, and this grateful country will do everything we can to help them recover. (Applause.) And we have said farewell to some very good men and women, who died for our freedom, and whose memory this nation will honor forever. \n",
      "\n",
      "One name we honor is Marine Corps Sergeant Byron Norwood of Pflugerville, Texas, who was killed during the assault on Fallujah. His mom, Janet, sent me a letter and told me how much Byron loved being a Marine, and how proud he was to be on the front line against terror. She wrote, \"When Byron was home the last time, I said that I wanted to protect him like I had since he was born. He just hugged me and said, 'You've done your job, Mom. Now it is my turn to protect you.'\" Ladies and gentlemen, with grateful hearts, we honor freedom's defenders, and our military families, represented here this evening by Sergeant Norwood's mom and dad, Janet and Bill Norwood. (Applause.) \n",
      "\n",
      "In these four years, Americans have seen the unfolding of large events. We have known times of sorrow, and hours of uncertainty, and days of victory. In all this history, even when we have disagreed, we have seen threads of purpose that unite us. The attack on freedom in our world has reaffirmed our confidence in freedom's power to change the world. We are all part of a great venture: To extend the promise of freedom in our country, to renew the values that sustain our liberty, and to spread the peace that freedom brings. \n",
      "\n",
      "As Franklin Roosevelt once reminded Americans, \"Each age is a dream that is dying, or one that is coming to birth.\" And we live in the country where the biggest dreams are born. The abolition of slavery was only a dream -- until it was fulfilled. The liberation of Europe from fascism was only a dream -- until it was achieved. The fall of imperial communism was only a dream -- until, one day, it was accomplished. Our generation has dreams of its own, and we also go forward with confidence. The road of Providence is uneven and unpredictable -- yet we know where it leads: It leads to freedom. \n",
      "\n",
      "Thank you, and may God bless America. (Applause.) \n",
      "\n",
      "END 10:03 P.M. EST \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"PRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\\n \\nJanuary 31, 2006\\n\\nTHE PRESIDENT: Thank you all.\", 'Mr. Speaker, Vice President Cheney, members of Congress, members of the Supreme Court and diplomatic corps, distinguished guests, and fellow citizens: Today our nation lost a beloved, graceful, courageous woman who called America to its founding ideals and carried on a noble dream.', 'Tonight we are comforted by the hope of a glad reunion with the husband who was taken so long ago, and we are grateful for the good life of Coretta Scott King.', '(Applause.)', 'President George W. Bush reacts to applause during his State of the Union Address at the Capitol, Tuesday, Jan.', '31, 2006.', \"White House photo by Eric DraperEvery time I'm invited to this rostrum, I'm humbled by the privilege, and mindful of the history we've seen together.\", 'We have gathered under this Capitol dome in moments of national mourning and national achievement.', 'We have served America through one of the most consequential periods of our history -- and it has been my honor to serve with you.', 'In a system of two parties, two chambers, and two elected branches, there will always be differences and debate.', 'But even tough debates can be conducted in a civil tone, and our differences cannot be allowed to harden into anger.', 'To confront the great issues before us, we must act in a spirit of goodwill and respect for one another -- and I will do my part.', 'Tonight the state of our Union is strong -- and together we will make it stronger.', '(Applause.)', 'In this decisive year, you and I will make choices that determine both the future and the character of our country.', 'We will choose to act confidently in pursuing the enemies of freedom -- or retreat from our duties in the hope of an easier life.', 'We will choose to build our prosperity by leading the world economy -- or shut ourselves off from trade and opportunity.', 'In a complex and challenging time, the road of isolationism and protectionism may seem broad and inviting -- yet it ends in danger and decline.', 'The only way to protect our people, the only way to secure the peace, the only way to control our destiny is by our leadership -- so the United States of America will continue to lead.', '(Applause.)', 'Abroad, our nation is committed to an historic, long-term goal -- we seek the end of tyranny in our world.', 'Some dismiss that goal as misguided idealism.', 'In reality, the future security of America depends on it.', 'On September the 11th, 2001, we found that problems originating in a failed and oppressive state 7,000 miles away could bring murder and destruction to our country.', 'Dictatorships shelter terrorists, and feed resentment and radicalism, and seek weapons of mass destruction.', 'Democracies replace resentment with hope, respect the rights of their citizens and their neighbors, and join the fight against terror.', \"Every step toward freedom in the world makes our country safer -- so we will act boldly in freedom's cause.\", '(Applause.)', 'Far from being a hopeless dream, the advance of freedom is the great story of our time.', 'In 1945, there were about two dozen lonely democracies in the world.', 'Today, there are 122.', \"And we're writing a new chapter in the story of self-government -- with women lining up to vote in Afghanistan, and millions of Iraqis marking their liberty with purple ink, and men and women from Lebanon to Egypt debating the rights of individuals and the necessity of freedom.\", 'At the start of 2006, more than half the people of our world live in democratic nations.', 'And we do not forget the other half -- in places like Syria and Burma, Zimbabwe, North Korea, and Iran -- because the demands of justice, and the peace of this world, require their freedom, as well.', '(Applause.)', 'President George W. Bush delivers his State of the Union Address at the Capitol, Tuesday, Jan.', '31, 2006.', 'White House photo by Eric Draper No one can deny the success of freedom, but some men rage and fight against it.', 'And one of the main sources of reaction and opposition is radical Islam -- the perversion by a few of a noble faith into an ideology of terror and death.', 'Terrorists like bin Laden are serious about mass murder -- and all of us must take their declared intentions seriously.', 'They seek to impose a heartless system of totalitarian control throughout the Middle East, and arm themselves with weapons of mass murder.', 'Their aim is to seize power in Iraq, and use it as a safe haven to launch attacks against America and the world.', 'Lacking the military strength to challenge us directly, the terrorists have chosen the weapon of fear.', 'When they murder children at a school in Beslan, or blow up commuters in London, or behead a bound captive, the terrorists hope these horrors will break our will, allowing the violent to inherit the Earth.', 'But they have miscalculated: We love our freedom, and we will fight to keep it.', '(Applause.)', 'In a time of testing, we cannot find security by abandoning our commitments and retreating within our borders.', 'If we were to leave these vicious attackers alone, they would not leave us alone.', 'They would simply move the battlefield to our own shores.', 'There is no peace in retreat.', 'And there is no honor in retreat.', 'By allowing radical Islam to work its will -- by leaving an assaulted world to fend for itself -- we would signal to all that we no longer believe in our own ideals, or even in our own courage.', 'But our enemies and our friends can be certain: The United States will not retreat from the world, and we will never surrender to evil.', '(Applause.)', 'America rejects the false comfort of isolationism.', 'We are the nation that saved liberty in Europe, and liberated death camps, and helped raise up democracies, and faced down an evil empire.', 'Once again, we accept the call of history to deliver the oppressed and move this world toward peace.', 'We remain on the offensive against terror networks.', 'We have killed or captured many of their leaders -- and for the others, their day will come.', 'President George W. Bush greets members of Congress after his State of the Union Address at the Capitol, Tuesday, Jan.', '31, 2006.', 'White House photo by Eric Draper We remain on the offensive in Afghanistan, where a fine President and a National Assembly are fighting terror while building the institutions of a new democracy.', \"We're on the offensive in Iraq, with a clear plan for victory.\", \"First, we're helping Iraqis build an inclusive government, so that old resentments will be eased and the insurgency will be marginalized.\", \"Second, we're continuing reconstruction efforts, and helping the Iraqi government to fight corruption and build a modern economy, so all Iraqis can experience the benefits of freedom.\", \"And, third, we're striking terrorist targets while we train Iraqi forces that are increasingly capable of defeating the enemy.\", 'Iraqis are showing their courage every day, and we are proud to be their allies in the cause of freedom.', '(Applause.)', 'Our work in Iraq is difficult because our enemy is brutal.', 'But that brutality has not stopped the dramatic progress of a new democracy.', 'In less than three years, the nation has gone from dictatorship to liberation, to sovereignty, to a constitution, to national elections.', 'At the same time, our coalition has been relentless in shutting off terrorist infiltration, clearing out insurgent strongholds, and turning over territory to Iraqi security forces.', 'I am confident in our plan for victory; I am confident in the will of the Iraqi people; I am confident in the skill and spirit of our military.', 'Fellow citizens, we are in this fight to win, and we are winning.', '(Applause.)', 'The road of victory is the road that will take our troops home.', 'As we make progress on the ground, and Iraqi forces increasingly take the lead, we should be able to further decrease our troop levels -- but those decisions will be made by our military commanders, not by politicians in Washington, D.C.', '(Applause.)', 'Our coalition has learned from our experience in Iraq.', \"We've adjusted our military tactics and changed our approach to reconstruction.\", 'Along the way, we have benefitted from responsible criticism and counsel offered by members of Congress of both parties.', 'In the coming year, I will continue to reach out and seek your good advice.', 'Yet, there is a difference between responsible criticism that aims for success, and defeatism that refuses to acknowledge anything but failure.', '(Applause.)', 'Hindsight alone is not wisdom, and second-guessing is not a strategy.', '(Applause.)', 'With so much in the balance, those of us in public office have a duty to speak with candor.', 'A sudden withdrawal of our forces from Iraq would abandon our Iraqi allies to death and prison, would put men like bin Laden and Zarqawi in charge of a strategic country, and show that a pledge from America means little.', 'Members of Congress, however we feel about the decisions and debates of the past, our nation has only one option: We must keep our word, defeat our enemies, and stand behind the American military in this vital mission.', '(Applause.)', 'Laura Bush is applauded as she is introduced Tuesday evening, Jan.', '31, 2006 during the State of the Union Address at United States Capitol in Washington.', 'White House photo by Eric Draper Our men and women in uniform are making sacrifices -- and showing a sense of duty stronger than all fear.', \"They know what it's like to fight house to house in a maze of streets, to wear heavy gear in the desert heat, to see a comrade killed by a roadside bomb.\", 'And those who know the costs also know the stakes.', 'Marine Staff Sergeant Dan Clay was killed last month fighting in Fallujah.', 'He left behind a letter to his family, but his words could just as well be addressed to every American.', 'Here is what Dan wrote: \"I know what honor is.', '... It has been an honor to protect and serve all of you.', 'I faced death with the secure knowledge that you would not have to....', 'Never falter!', 'Don\\'t hesitate to honor and support those of us who have the honor of protecting that which is worth protecting.\"', \"Staff Sergeant Dan Clay's wife, Lisa, and his mom and dad, Sara Jo and Bud, are with us this evening.\", 'Welcome.', '(Applause.)', 'Our nation is grateful to the fallen, who live in the memory of our country.', \"We're grateful to all who volunteer to wear our nation's uniform -- and as we honor our brave troops, let us never forget the sacrifices of America's military families.\", '(Applause.)', 'Our offensive against terror involves more than military action.', 'Ultimately, the only way to defeat the terrorists is to defeat their dark vision of hatred and fear by offering the hopeful alternative of political freedom and peaceful change.', 'So the United States of America supports democratic reform across the broader Middle East.', 'Elections are vital, but they are only the beginning.', 'Raising up a democracy requires the rule of law, and protection of minorities, and strong, accountable institutions that last longer than a single vote.', 'The great people of Egypt have voted in a multi-party presidential election -- and now their government should open paths of peaceful opposition that will reduce the appeal of radicalism.', 'The Palestinian people have voted in elections.', 'And now the leaders of Hamas must recognize Israel, disarm, reject terrorism, and work for lasting peace.', '(Applause.)', 'Saudi Arabia has taken the first steps of reform -- now it can offer its people a better future by pressing forward with those efforts.', 'Democracies in the Middle East will not look like our own, because they will reflect the traditions of their own citizens.', 'Yet liberty is the future of every nation in the Middle East, because liberty is the right and hope of all humanity.', '(Applause.)', 'President George W. Bush waves toward the upper visitors gallery of the House Chamber following his State of the Union remarks Tuesday, Jan.', '31, 2006 at the United States Capitol.', 'White House photo by Eric Draper The same is true of Iran, a nation now held hostage by a small clerical elite that is isolating and repressing its people.', 'The regime in that country sponsors terrorists in the Palestinian territories and in Lebanon -- and that must come to an end.', '(Applause.)', 'The Iranian government is defying the world with its nuclear ambitions, and the nations of the world must not permit the Iranian regime to gain nuclear weapons.', '(Applause.)', 'America will continue to rally the world to confront these threats.', 'Tonight, let me speak directly to the citizens of Iran: America respects you, and we respect your country.', 'We respect your right to choose your own future and win your own freedom.', 'And our nation hopes one day to be the closest of friends with a free and democratic Iran.', '(Applause.)', 'To overcome dangers in our world, we must also take the offensive by encouraging economic progress, and fighting disease, and spreading hope in hopeless lands.', 'Isolationism would not only tie our hands in fighting enemies, it would keep us from helping our friends in desperate need.', 'We show compassion abroad because Americans believe in the God-given dignity and worth of a villager with HIV/AIDS, or an infant with malaria, or a refugee fleeing genocide, or a young girl sold into slavery.', 'We also show compassion abroad because regions overwhelmed by poverty, corruption, and despair are sources of terrorism, and organized crime, and human trafficking, and the drug trade.', 'In recent years, you and I have taken unprecedented action to fight AIDS and malaria, expand the education of girls, and reward developing nations that are moving forward with economic and political reform.', 'For people everywhere, the United States is a partner for a better life.', 'Short-changing these efforts would increase the suffering and chaos of our world, undercut our long-term security, and dull the conscience of our country.', 'I urge members of Congress to serve the interests of America by showing the compassion of America.', 'Our country must also remain on the offensive against terrorism here at home.', 'The enemy has not lost the desire or capability to attack us.', 'Fortunately, this nation has superb professionals in law enforcement, intelligence, the military, and homeland security.', 'These men and women are dedicating their lives, protecting us all, and they deserve our support and our thanks.', '(Applause.)', 'They also deserve the same tools they already use to fight drug trafficking and organized crime -- so I ask you to reauthorize the Patriot Act.', '(Applause.)', 'It is said that prior to the attacks of September the 11th, our government failed to connect the dots of the conspiracy.', 'We now know that two of the hijackers in the United States placed telephone calls to al Qaeda operatives overseas.', 'But we did not know about their plans until it was too late.', 'So to prevent another attack -- based on authority given to me by the Constitution and by statute -- I have authorized a terrorist surveillance program to aggressively pursue the international communications of suspected al Qaeda operatives and affiliates to and from America.', 'Previous Presidents have used the same constitutional authority I have, and federal courts have approved the use of that authority.', 'Appropriate members of Congress have been kept informed.', 'The terrorist surveillance program has helped prevent terrorist attacks.', 'It remains essential to the security of America.', 'If there are people inside our country who are talking with al Qaeda, we want to know about it, because we will not sit back and wait to be hit again.', '(Applause.)', 'In all these areas -- from the disruption of terror networks, to victory in Iraq, to the spread of freedom and hope in troubled regions -- we need the support of our friends and allies.', 'To draw that support, we must always be clear in our principles and willing to act.', 'The only alternative to American leadership is a dramatically more dangerous and anxious world.', 'Yet we also choose to lead because it is a privilege to serve the values that gave us birth.', 'American leaders -- from Roosevelt to Truman to Kennedy to Reagan -- rejected isolation and retreat, because they knew that America is always more secure when freedom is on the march.', 'Our own generation is in a long war against a determined enemy -- a war that will be fought by Presidents of both parties, who will need steady bipartisan support from the Congress.', 'And tonight I ask for yours.', 'Together, let us protect our country, support the men and women who defend us, and lead this world toward freedom.', '(Applause.)', 'Here at home, America also has a great opportunity: We will build the prosperity of our country by strengthening our economic leadership in the world.', 'Our economy is healthy and vigorous, and growing faster than other major industrialized nations.', 'In the last two-and-a-half years, America has created 4.6 million new jobs -- more than Japan and the European Union combined.', '(Applause.)', 'Even in the face of higher energy prices and natural disasters, the American people have turned in an economic performance that is the envy of the world.', 'The American economy is preeminent, but we cannot afford to be complacent.', \"In a dynamic world economy, we are seeing new competitors, like China and India, and this creates uncertainty, which makes it easier to feed people's fears.\", \"So we're seeing some old temptations return.\", 'Protectionists want to escape competition, pretending that we can keep our high standard of living while walling off our economy.', 'Others say that the government needs to take a larger role in directing the economy, centralizing more power in Washington and increasing taxes.', 'We hear claims that immigrants are somehow bad for the economy -- even though this economy could not function without them.', '(Applause.)', 'All these are forms of economic retreat, and they lead in the same direction -- toward a stagnant and second-rate economy.', 'Tonight I will set out a better path: an agenda for a nation that competes with confidence; an agenda that will raise standards of living and generate new jobs.', 'Americans should not fear our economic future, because we intend to shape it.', 'Keeping America competitive begins with keeping our economy growing.', 'And our economy grows when Americans have more of their own money to spend, save, and invest.', 'In the last five years, the tax relief you passed has left $880 billion in the hands of American workers, investors, small businesses, and families -- and they have used it to help produce more than four years of uninterrupted economic growth.', '(Applause.)', 'Yet the tax relief is set to expire in the next few years.', 'If we do nothing, American families will face a massive tax increase they do not expect and will not welcome.', 'Because America needs more than a temporary expansion, we need more than temporary tax relief.', 'I urge the Congress to act responsibly, and make the tax cuts permanent.', '(Applause.)', 'Keeping America competitive requires us to be good stewards of tax dollars.', \"Every year of my presidency, we've reduced the growth of non-security discretionary spending, and last year you passed bills that cut this spending.\", 'This year my budget will cut it again, and reduce or eliminate more than 140 programs that are performing poorly or not fulfilling essential priorities.', 'By passing these reforms, we will save the American taxpayer another $14 billion next year, and stay on track to cut the deficit in half by 2009.', '(Applause.)', 'I am pleased that members of Congress are working on earmark reform, because the federal budget has too many special interest projects.', '(Applause.)', 'And we can tackle this problem together, if you pass the line-item veto.', '(Applause.)', 'We must also confront the larger challenge of mandatory spending, or entitlements.', \"This year, the first of about 78 million baby boomers turn 60, including two of my Dad's favorite people -- me and President Clinton.\", '(Laughter.)', 'This milestone is more than a personal crisis -- (laughter) -- it is a national challenge.', 'The retirement of the baby boom generation will put unprecedented strains on the federal government.', 'By 2030, spending for Social Security, Medicare and Medicaid alone will be almost 60 percent of the entire federal budget.', 'And that will present future Congresses with impossible choices -- staggering tax increases, immense deficits, or deep cuts in every category of spending.', 'Congress did not act last year on my proposal to save Social Security -- (applause) -- yet the rising cost of entitlements is a problem that is not going away.', '(Applause.)', 'And every year we fail to act, the situation gets worse.', 'So tonight, I ask you to join me in creating a commission to examine the full impact of baby boom retirements on Social Security, Medicare, and Medicaid.', 'This commission should include members of Congress of both parties, and offer bipartisan solutions.', 'We need to put aside partisan politics and work together and get this problem solved.', '(Applause.)', 'Keeping America competitive requires us to open more markets for all that Americans make and grow.', 'One out of every five factory jobs in America is related to global trade, and we want people everywhere to buy American.', 'With open markets and a level playing field, no one can out-produce or out-compete the American worker.', '(Applause.)', 'Keeping America competitive requires an immigration system that upholds our laws, reflects our values, and serves the interests of our economy.', 'Our nation needs orderly and secure borders.', '(Applause.)', 'To meet this goal, we must have stronger immigration enforcement and border protection.', '(Applause.)', 'And we must have a rational, humane guest worker program that rejects amnesty, allows temporary jobs for people who seek them legally, and reduces smuggling and crime at the border.', '(Applause.)', 'Keeping America competitive requires affordable health care.', '(Applause.)', 'Our government has a responsibility to provide health care for the poor and the elderly, and we are meeting that responsibility.', '(Applause.)', 'For all Americans -- for all Americans, we must confront the rising cost of care, strengthen the doctor-patient relationship, and help people afford the insurance coverage they need.', '(Applause.)', 'We will make wider use of electronic records and other health information technology, to help control costs and reduce dangerous medical errors.', 'We will strengthen health savings accounts -- making sure individuals and small business employees can buy insurance with the same advantages that people working for big businesses now get.', '(Applause.)', 'We will do more to make this coverage portable, so workers can switch jobs without having to worry about losing their health insurance.', '(Applause.)', 'And because lawsuits are driving many good doctors out of practice -- leaving women in nearly 1,500 American counties without a single OB/GYN -- I ask the Congress to pass medical liability reform this year.', '(Applause.)', 'Keeping America competitive requires affordable energy.', 'And here we have a serious problem: America is addicted to oil, which is often imported from unstable parts of the world.', 'The best way to break this addiction is through technology.', 'Since 2001, we have spent nearly $10 billion to develop cleaner, cheaper, and more reliable alternative energy sources -- and we are on the threshold of incredible advances.', 'So tonight, I announce the Advanced Energy Initiative -- a 22-percent increase in clean-energy research -- at the Department of Energy, to push for breakthroughs in two vital areas.', 'To change how we power our homes and offices, we will invest more in zero-emission coal-fired plants, revolutionary solar and wind technologies, and clean, safe nuclear energy.', '(Applause.)', 'We must also change how we power our automobiles.', 'We will increase our research in better batteries for hybrid and electric cars, and in pollution-free cars that run on hydrogen.', \"We'll also fund additional research in cutting-edge methods of producing ethanol, not just from corn, but from wood chips and stalks, or switch grass.\", 'Our goal is to make this new kind of ethanol practical and competitive within six years.', '(Applause.)', 'Breakthroughs on this and other new technologies will help us reach another great goal: to replace more than 75 percent of our oil imports from the Middle East by 2025.', '(Applause.)', 'By applying the talent and technology of America, this country can dramatically improve our environment, move beyond a petroleum-based economy, and make our dependence on Middle Eastern oil a thing of the past.', '(Applause.)', 'And to keep America competitive, one commitment is necessary above all: We must continue to lead the world in human talent and creativity.', \"Our greatest advantage in the world has always been our educated, hardworking, ambitious people -- and we're going to keep that edge.\", \"Tonight I announce an American Competitiveness Initiative, to encourage innovation throughout our economy, and to give our nation's children a firm grounding in math and science.\", '(Applause.)', 'First, I propose to double the federal commitment to the most critical basic research programs in the physical sciences over the next 10 years.', \"This funding will support the work of America's most creative minds as they explore promising areas such as nanotechnology, supercomputing, and alternative energy sources.\", 'Second, I propose to make permanent the research and development tax credit -- (applause) -- to encourage bolder private-sector initiatives in technology.', 'With more research in both the public and private sectors, we will improve our quality of life -- and ensure that America will lead the world in opportunity and innovation for decades to come.', '(Applause.)', 'Third, we need to encourage children to take more math and science, and to make sure those courses are rigorous enough to compete with other nations.', \"We've made a good start in the early grades with the No Child Left Behind Act, which is raising standards and lifting test scores across our country.\", 'Tonight I propose to train 70,000 high school teachers to lead advanced-placement courses in math and science, bring 30,000 math and science professionals to teach in classrooms, and give early help to students who struggle with math, so they have a better chance at good, high-wage jobs.', \"If we ensure that America's children succeed in life, they will ensure that America succeeds in the world.\", '(Applause.)', 'Preparing our nation to compete in the world is a goal that all of us can share.', 'I urge you to support the American Competitiveness Initiative, and together we will show the world what the American people can achieve.', 'America is a great force for freedom and prosperity.', 'Yet our greatness is not measured in power or luxuries, but by who we are and how we treat one another.', 'So we strive to be a compassionate, decent, hopeful society.', 'In recent years, America has become a more hopeful nation.', 'Violent crime rates have fallen to their lowest levels since the 1970s.', 'Welfare cases have dropped by more than half over the past decade.', 'Drug use among youth is down 19 percent since 2001.', 'There are fewer abortions in America than at any point in the last three decades, and the number of children born to teenage mothers has been falling for a dozen years in a row.', '(Applause.)', 'These gains are evidence of a quiet transformation -- a revolution of conscience, in which a rising generation is finding that a life of personal responsibility is a life of fulfillment.', 'Government has played a role.', 'Wise policies, such as welfare reform and drug education and support for abstinence and adoption have made a difference in the character of our country.', 'And everyone here tonight, Democrat and Republican, has a right to be proud of this record.', '(Applause.)', 'Yet many Americans, especially parents, still have deep concerns about the direction of our culture, and the health of our most basic institutions.', \"They're concerned about unethical conduct by public officials, and discouraged by activist courts that try to redefine marriage.\", 'They worry about children in our society who need direction and love, and about fellow citizens still displaced by natural disaster, and about suffering caused by treatable diseases.', 'As we look at these challenges, we must never give in to the belief that America is in decline, or that our culture is doomed to unravel.', 'The American people know better than that.', 'We have proven the pessimists wrong before -- and we will do it again.', '(Applause.)', 'A hopeful society depends on courts that deliver equal justice under the law.', 'The Supreme Court now has two superb new members -- new members on its bench: Chief Justice John Roberts and Justice Sam Alito.', '(Applause.)', 'I thank the Senate for confirming both of them.', 'I will continue to nominate men and women who understand that judges must be servants of the law, and not legislate from the bench.', '(Applause.)', 'Today marks the official retirement of a very special American.', \"For 24 years of faithful service to our nation, the United States is grateful to Justice Sandra Day O'Connor.\", '(Applause.)', 'A hopeful society has institutions of science and medicine that do not cut ethical corners, and that recognize the matchless value of every life.', 'Tonight I ask you to pass legislation to prohibit the most egregious abuses of medical research: human cloning in all its forms, creating or implanting embryos for experiments, creating human-animal hybrids, and buying, selling, or patenting human embryos.', 'Human life is a gift from our Creator -- and that gift should never be discarded, devalued or put up for sale.', '(Applause.)', 'A hopeful society expects elected officials to uphold the public trust.', '(Applause.)', 'Honorable people in both parties are working on reforms to strengthen the ethical standards of Washington -- I support your efforts.', 'Each of us has made a pledge to be worthy of public responsibility -- and that is a pledge we must never forget, never dismiss, and never betray.', '(Applause.)', 'As we renew the promise of our institutions, let us also show the character of America in our compassion and care for one another.', 'A hopeful society gives special attention to children who lack direction and love.', \"Through the Helping America's Youth Initiative, we are encouraging caring adults to get involved in the life of a child -- and this good work is being led by our First Lady, Laura Bush.\", '(Applause.)', \"This year we will add resources to encourage young people to stay in school, so more of America's youth can raise their sights and achieve their dreams.\", \"A hopeful society comes to the aid of fellow citizens in times of suffering and emergency -- and stays at it until they're back on their feet.\", 'So far the federal government has committed $85 billion to the people of the Gulf Coast and New Orleans.', \"We're removing debris and repairing highways and rebuilding stronger levees.\", \"We're providing business loans and housing assistance.\", 'Yet as we meet these immediate needs, we must also address deeper challenges that existed before the storm arrived.', 'In New Orleans and in other places, many of our fellow citizens have felt excluded from the promise of our country.', 'The answer is not only temporary relief, but schools that teach every child, and job skills that bring upward mobility, and more opportunities to own a home and start a business.', 'As we recover from a disaster, let us also work for the day when all Americans are protected by justice, equal in hope, and rich in opportunity.', '(Applause.)', 'A hopeful society acts boldly to fight diseases like HIV/AIDS, which can be prevented, and treated, and defeated.', 'More than a million Americans live with HIV, and half of all AIDS cases occur among African Americans.', 'I ask Congress to reform and reauthorize the Ryan White Act, and provide new funding to states, so we end the waiting lists for AIDS medicines in America.', '(Applause.)', 'We will also lead a nationwide effort, working closely with African American churches and faith-based groups, to deliver rapid HIV tests to millions, end the stigma of AIDS, and come closer to the day when there are no new infections in America.', '(Applause.)', \"Fellow citizens, we've been called to leadership in a period of consequence.\", \"We've entered a great ideological conflict we did nothing to invite.\", 'We see great changes in science and commerce that will influence all our lives.', 'Sometimes it can seem that history is turning in a wide arc, toward an unknown shore.', 'Yet the destination of history is determined by human action, and every great movement of history comes to a point of choosing.', 'Lincoln could have accepted peace at the cost of disunity and continued slavery.', 'Martin Luther King could have stopped at Birmingham or at Selma, and achieved only half a victory over segregation.', 'The United States could have accepted the permanent division of Europe, and been complicit in the oppression of others.', 'Today, having come far in our own historical journey, we must decide: Will we turn back, or finish well?', 'Before history is written down in books, it is written in courage.', 'Like Americans before us, we will show that courage and we will finish well.', \"We will lead freedom's advance.\", 'We will compete and excel in the global economy.', 'We will renew the defining moral commitments of this land.', 'And so we move forward -- optimistic about our country, faithful to its cause, and confident of the victories to come.', 'May God bless America.', '(Applause.)']\n"
     ]
    }
   ],
   "source": [
    "# Now we are training the PunktSentenceTokenizer on the train_text\n",
    "custom_text_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "# Then we actually tokenize like this\n",
    "tokenized = custom_text_tokenizer.tokenize(sample_text)\n",
    "print(tokenized) # We get a list of tokenized sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
      "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Now we can finish up this part of speech tagging script by creating a function that will run through and tag all \n",
    "# of the parts of speech per sentence like so,\n",
    "\n",
    "# Here tokenized contains all the sentences.\n",
    "# nltk.pos_tag will tag the word with correct tags\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()\n",
    "# Here the output should be a list of tuples,\n",
    "# where the first element in the tuple is the word, and the second is the part of speech tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VIDEO-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking with NLTK\n",
    "\n",
    "we know the parts of speech, we can do what is called chunking, and group words into hopefully meaningful chunks.\n",
    "**One of the main goals of chunking is to group into what are known as \"noun phrases.\" These are phrases of one or more words that contain a noun, maybe some descriptive words, maybe a verb, and maybe something like an adverb. The idea is to group nouns with the words that are in relation to them.** \n",
    "\n",
    "In order to chunk, we combine the part of speech tags with regular expressions. \n",
    "regular expressions :   \n",
    "**+ = match 1 or more **  \n",
    "**? = match 0 or 1 repetitions**    \n",
    "**\\* = match 0 or MORE repetitions**\t  \n",
    "**. = Any character except a new line**\n",
    "\n",
    "**part of speech tags are denoted with the \"<\" and \">\" and we can also place regular expressions within the tags themselves, so account for things like \"all nouns\"(< N.*>)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "  'S/POS\n",
      "  (Chunk ADDRESS/NNP)\n",
      "  BEFORE/IN\n",
      "  (Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP UNION/NNP January/NNP)\n",
      "  31/CD\n",
      "  ,/,\n",
      "  2006/CD\n",
      "  (Chunk THE/NNP PRESIDENT/NNP)\n",
      "  :/:\n",
      "  (Chunk Thank/NNP)\n",
      "  you/PRP\n",
      "  all/DT\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "  'S/POS\n",
      "  (Chunk ADDRESS/NNP)\n",
      "  BEFORE/IN\n",
      "  (Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP UNION/NNP January/NNP)\n",
      "  31/CD\n",
      "  ,/,\n",
      "  2006/CD\n",
      "  (Chunk THE/NNP PRESIDENT/NNP)\n",
      "  :/:\n",
      "  (Chunk Thank/NNP)\n",
      "  you/PRP\n",
      "  all/DT\n",
      "  ./.)\n",
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "(Chunk ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk THE/NNP UNION/NNP January/NNP)\n",
      "(Chunk THE/NNP PRESIDENT/NNP)\n",
      "(Chunk Thank/NNP)\n",
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "(Chunk ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk THE/NNP UNION/NNP January/NNP)\n",
      "(Chunk THE/NNP PRESIDENT/NNP)\n",
      "(Chunk Thank/NNP)\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:1]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\" # This is the main line\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            chunked.draw()     \n",
    "            print(chunked)\n",
    "            for subtree in chunked.subtrees():\n",
    "                print(subtree)\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                print(subtree)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "# The main line can be broken down and explained as:\n",
    "# <RB.?>* = \"0 or more of any tense of adverb,\" followed by:\n",
    "# <VB.?>* = \"0 or more of any tense of verb,\" followed by:\n",
    "# <NNP>+ = \"One or more proper nouns,\" followed by\n",
    "# <NN>? = \"zero or one singular noun.\"\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but what if we want to access this data via our program? **Well, what is happening here is our \"chunked\" variable is an NLTK tree. Each \"chunk\" and \"non chunk\" is a \"subtree\" of the tree.**\n",
    "We can reference these by doing something like chunked.subtrees. Next, we might be only interested in getting just the chunks, ignoring the rest. We can use the filter parameter in the chunked.subtrees() call.\n",
    "\n",
    "**Keep in mind, this isn't \"Chunk\" as in the NLTK chunk attribute... this is \"Chunk\" literally because that's the label we gave it here: chunkGram = r\"\"\"Chunk: {pattern}\"\"\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinking with NLTK\n",
    "\n",
    "After a lot of chunking, you have some words in your chunk you still do not want, but you have no idea how to get rid of them by chunking. You may find that chinking is your solution.\n",
    "**Chinking is a lot like chunking, it is basically a way for you to remove a chunk from a chunk. The chunk that you remove from your chunk is your chink.**\n",
    "\n",
    "**you just denote the chink, after the chunk, with }{ instead of the chunk's {}.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:1]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "\n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+} \n",
    "                                         }<VB.?|IN|DT|TO>+{\"\"\" # Here is a chunk then a chink with }{\n",
    "            #This means we're removing from the chink one or more verbs, prepositions, determiners, \n",
    "            #or the word 'to'.\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition with NLTK\n",
    "\n",
    "One of the most major forms of chunking in natural language processing is called \"Named Entity Recognition.\" \n",
    "**The idea is to have the machine immediately be able to pull out \"entities\" like people, places, things, locations, monetary figures, and more.** There are two major options with NLTK's named entity recognition: **either recognize all named entities**, or **recognize named entities as their respective type, like people, places, locations, etc**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:1]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            namedEnt = nltk.ne_chunk(tagged, binary=False)\n",
    "            namedEnt.draw()\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "# the option of binary = True, this means either something is a named entity, or not\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When Binary is False, it picked up the same things, but wound up splitting up terms like White House into \"White\" and \"House\" as if they were different, whereas we could see in the binary = True option, the named entity recognition was correct to say White House was part of the same named entity.**\n",
    "\n",
    "Here are the types of Named Entities that you can get **if you have binary as false:**\n",
    "\n",
    "**NE Type and Examples**    \n",
    "ORGANIZATION - Georgia-Pacific Corp., WHO   \n",
    "PERSON - Eddy Bonte, President Obama      \n",
    "LOCATION - Murray River, Mount Everest    \n",
    "DATE - June, 2008-06-29     \n",
    "TIME - two fifty a m, 1:30 p.m.     \n",
    "MONEY - 175 million Canadian Dollars, GBP 10.40     \n",
    "PERCENT - twenty pct, 18.75 %    \n",
    "FACILITY - Washington Monument, Stonehenge    \n",
    "GPE - South East Asia, Midlothian   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing with NLTK\n",
    "\n",
    "A very similar operation to stemming is called lemmatizing. **Stemming can often create non-existent words, whereas lemmas are actual words.** **So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma.** Some times you will wind up with a very similar word, but sometimes, you will wind up with a completely different word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "best\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"run\",'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The only major thing to note is that lemmatize takes a part of speech parameter, \"pos.\"** **If not supplied, the default is \"noun.\" This means that an attempt will be made to find the closest noun**, which can create trouble for you. Keep this in mind if you use lemmatizing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The corpora with NLTK\n",
    "**The NLTK corpus is a massive dump of all kinds of natural language data sets that are definitely worth taking a look at.** These files are plain text files for the most part, some are XML and some are other formats, but they are all accessible by you manually, or via the module and Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sparsh/anaconda2/envs/py35/lib/python3.5/site-packages/nltk/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__file__) # This give us the location of data.py in which the location of nltk_data is present.\n",
    "                     # From their we can have a look at corpara and other stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The King James Bible]\n",
      "\n",
      "The Old Testament of the King James Bible\n",
      "\n",
      "The First Book of Moses:  Called Genesis\n",
      "\n",
      "\n",
      "1:1 In the beginning God created the heaven and the earth.\n",
      "1:2 And the earth was without form, and void; and darkness was upon\n",
      "the face of the deep.\n",
      "And the Spirit of God moved upon the face of the\n",
      "waters.\n",
      "1:3 And God said, Let there be light: and there was light.\n",
      "1:4 And God saw the light, that it was good: and God divided the light\n",
      "from the darkness.\n"
     ]
    }
   ],
   "source": [
    "# sample text\n",
    "sample = gutenberg.raw(\"bible-kjv.txt\")\n",
    "\n",
    "tok = sent_tokenize(sample)\n",
    "\n",
    "for x in range(5):\n",
    "    print(tok[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the more advanced data sets in here is \"wordnet.\" **Wordnet is a collection of words, definitions, examples of their use, synonyms, antonyms, and more.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet with NLTK\n",
    "\n",
    "**WordNet is a lexical database for the English language, which was created by Princeton, and is part of the NLTK corpus.** You can use WordNet alongside the NLTK module to find the meanings of words, synonyms, antonyms, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('plan.n.01'), Synset('program.n.02'), Synset('broadcast.n.02'), Synset('platform.n.02'), Synset('program.n.05'), Synset('course_of_study.n.01'), Synset('program.n.07'), Synset('program.n.08'), Synset('program.v.01'), Synset('program.v.02')]\n"
     ]
    }
   ],
   "source": [
    "syns = wordnet.synsets(\"program\")    # Here we are searching for meaning of the word in the wordnet\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan.n.01\n",
      "plan\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].name())                  # example of sysnet\n",
    "print(syns[0].lemmas()[0].name())      # this gives us only a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a series of steps to be carried out or goals to be accomplished\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].definition())   # Examples of the defination of the word choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].examples())     # Examples of the word in choosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lemmas will be synonyms, and then you can use .antonyms to find the antonyms to the lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trade_good', 'secure', 'adept', 'in_force', 'serious', 'right', 'proficient', 'expert', 'salutary', 'in_effect', 'dependable', 'full', 'skillful', 'dear', 'estimable', 'ripe', 'beneficial', 'honest', 'near', 'goodness', 'soundly', 'safe', 'respectable', 'thoroughly', 'upright', 'practiced', 'well', 'good', 'unspoiled', 'effective', 'skilful', 'sound', 'unspoilt', 'undecomposed', 'commodity', 'honorable', 'just'}\n",
      "{'bad', 'evil', 'ill', 'evilness', 'badness'}\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you can see, we got many more synonyms than antonyms, since we just looked up the antonym for the first lemma, but you could easily balance this buy also doing the exact same process for the term \"bad.\"**\n",
    "\n",
    "Next, **we can also easily use WordNet to compare the similarity of two words and their tenses, by incorporating the Wu and Palmer method for semantic related-ness**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')  # This ship.n.01. means ship.nouns.1st \n",
    "w2 = wordnet.synset('boat.n.01')\n",
    "print(w1.wup_similarity(w2))      # comparing similarity between two words using wup method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')   \n",
    "w2 = wordnet.synset('car.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('cat.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with NLTK\n",
    "\n",
    "To do this, we're going to start by trying to use the movie reviews database that is part of the NLTK corpus. From there we'll try to use words as \"features\" which are a part of either a positive or negative movie review. The NLTK corpus movie_reviews data set has the reviews, and they are labeled already as positive or negative. This means we can train and test with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "# Basically, in plain English, the above code is translated to: In each category (we have pos or neg), \n",
    "# take all of the file IDs (each review has its own ID), then store the word_tokenized version (a list of words) \n",
    "# for the file ID, followed by the positive or negative label in one big list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['1992', \"'\", 's', 'alien3', 'marked', 'not', 'only', 'the', 'death', '(', 'by', 'suicide', ')', 'of', 'its', 'popular', 'protagonist', ',', 'ellen', 'ripley', '(', 'sigourney', 'weaver', ')', ',', 'but', ',', 'in', 'many', 'ways', ',', 'the', 'alien', 'franchise', 'itself', '--', 'box', 'office', 'receipts', 'were', 'anemic', ',', 'thanks', 'to', 'poor', 'audience', 'word', 'of', 'mouth', ';', 'and', 'the', 'critics', 'who', 'rallied', 'around', 'the', 'first', 'two', 'installments', ',', '1979', \"'\", 's', 'alien', 'and', '1986', \"'\", 's', 'aliens', ',', 'savaged', 'david', 'fincher', \"'\", 's', 'slog', 'of', 'a', 'sendoff', '(', 'myself', 'included', ')', '.', 'hence', ',', 'weaver', ',', 'director', 'jean', '-', 'pierre', 'jeunet', ',', 'and', 'the', 'others', 'behind', 'alien', 'resurrection', 'faced', 'a', 'two', '-', 'fold', 'challenge', '--', 'not', 'only', 'somehow', 'resurrect', 'ripley', ',', 'but', 'also', 'rescue', 'this', 'once', '-', 'profitable', 'series', 'from', 'the', 'scrap', 'heap', '.', 'despite', 'the', 'odds', ',', 'they', 'have', 'succeeded', ',', 'even', 'if', 'the', 'entertaining', 'new', 'installment', 'does', 'not', 'measure', 'up', 'to', 'the', 'excellent', 'first', 'two', '.', 'writer', 'joss', 'whedon', 'devises', 'a', 'quick', ',', 'easy', ',', 'and', 'painless', 'answer', 'to', 'the', 'dead', 'ripley', 'problem', '--', 'clone', 'her', ',', 'which', 'is', 'what', 'shady', 'military', 'scientists', 'do', 'using', 'some', 'blood', 'left', 'behind', 'on', 'fiorina', '161', ',', 'the', 'prison', 'planet', 'of', 'the', 'third', 'film', '.', 'that', 'done', ',', 'the', '_real_', 'challenge', 'presents', 'itself', '--', 'what', 'do', 'with', 'her', '.', 'alien', 'introduced', 'ripley', 'as', 'smart', 'and', 'resourceful', ';', 'aliens', 'simultaneously', 'toughened', 'her', 'up', 'and', 'made', 'her', 'more', 'vulnerable', ',', 'exploring', 'her', 'maternal', 'side', ';', 'alien3', 'saw', 'her', 'undergoing', 'the', 'seven', 'stages', 'of', 'death', '.', 'what', 'could', 'be', 'next', '?', 'whedon', 'comes', 'up', 'with', 'a', 'clever', 'spin', ':', 'since', 'the', 'original', 'ripley', 'died', 'while', 'impregnated', 'with', 'an', 'alien', 'queen', ',', 'the', 'blood', 'used', 'for', 'the', 'clone', 'is', 'also', '\"', 'infected', '\"', 'with', 'alien', 'dna', '.', 'so', 'the', 'new', 'ripley', 'is', ',', 'indeed', ',', 'new', '--', 'a', 'human', '/', 'alien', 'hybrid', 'blessed', 'with', 'heightened', 'instincts', 'and', 'strength', ',', 'a', 'psychic', 'bond', 'with', 'the', 'deadly', 'species', ',', 'and', 'a', 'more', 'predatory', 'attitude', '.', 'unfortunately', ',', 'that', 'is', 'where', 'alien', 'resurrection', \"'\", 's', 'clever', 'streak', 'in', 'writing', 'stops', '.', 'the', 'alien', 'series', 'is', 'known', 'for', 'having', 'stronger', 'stories', 'than', 'most', 'creature', 'features', '.', 'but', 'the', 'story', 'in', 'resurrection', 'is', 'more', 'of', 'an', 'afterthought', '.', 'the', 'movie', 'begins', 'with', 'a', 'plot', 'involving', 'some', 'military', 'types', 'attempting', 'to', 'train', 'aliens', 'to', 'do', 'their', 'bidding', ',', 'but', 'once', 'the', 'creatures', 'break', 'free', ',', 'it', 'is', 'once', 'again', 'ripley', 'and', 'a', 'ragtag', 'crew', '(', 'this', 'time', 'a', 'bunch', 'of', 'interstellar', 'smugglers', ',', 'including', 'tough', 'waif', 'call', ',', 'played', 'by', 'a', 'game', 'winona', 'ryder', ')', 'trying', 'to', 'exterminate', 'them', '.', 'and', 'the', 'alien', 'ripley', 'scenario', 'is', 'ultimately', 'not', 'exploited', 'to', 'its', 'full', 'potential', ';', 'i', 'would', 'have', 'liked', 'deeper', 'exploration', 'into', 'the', 'quandary', 'of', 'becoming', 'one', 'of', 'the', 'species', 'she', 'has', 'spent', 'her', 'entire', 'life', 'trying', 'to', 'destroy', '.', 'while', 'the', 'settling', 'into', 'tried', '-', 'and', '-', 'true', 'formula', 'is', 'a', 'little', 'disconcerting', ',', 'the', 'formula', 'is', 'tried', '-', 'and', '-', 'true', 'for', 'a', 'reason', ',', 'and', 'jeunet', 'tackles', 'the', 'proceedings', 'with', 'giddy', 'abandon', '.', 'the', 'alien', ',', 'after', 'all', 'these', 'years', ',', 'is', 'still', 'terrifying', ',', 'and', 'a', 'new', 'breed', 'that', 'is', 'introduced', 'is', 'no', 'less', 'so', '.', 'the', 'violence', 'is', 'appropriately', 'grisly', 'and', 'extreme', ',', 'and', 'the', 'action', 'set', 'pieces', 'are', 'suspenseful', 'and', 'exciting', ',', 'most', 'notably', 'an', 'extended', 'underwater', 'sequence', '.', 'the', 'film', 'is', 'absolutely', 'mesmerizing', 'visually', ',', 'thanks', 'to', 'the', 'solid', 'work', 'done', 'by', 'production', 'designer', 'nigel', 'phelps', 'and', 'cinematographer', 'darius', 'khondji', '.', 'as', 'technically', 'adept', 'as', 'jeunet', \"'\", 's', 'direction', 'is', ',', 'perhaps', 'his', '(', 'and', ',', 'for', 'that', 'matter', ',', 'whedon', \"'\", 's', ')', 'greatest', 'contribution', 'is', 'the', 'infusion', 'of', 'humor', 'into', 'this', 'notably', 'downbeat', 'and', 'serious', 'series', '.', 'a', 'sense', 'of', 'humor', 'may', 'seem', 'to', 'go', 'against', 'everything', 'this', 'horror', 'show', 'stands', 'for', ',', 'but', 'the', 'self', '-', 'awareness', 'of', 'the', 'excess', 'just', 'adds', 'to', 'the', 'fun', '.', 'no', ',', 'alien', 'resurrection', 'is', 'not', 'the', 'great', 'film', 'that', 'ridley', 'scott', \"'\", 's', 'alien', 'or', 'the', 'even', 'greater', 'film', 'that', 'james', 'cameron', \"'\", 's', 'aliens', 'was', '.', 'but', 'after', 'the', 'dauntingly', 'slow', 'gloom', 'and', 'doom', 'of', 'fincher', \"'\", 's', 'alien3', ',', 'jeunet', \"'\", 's', 'resurrection', 'is', 'a', 'welcome', 'return', 'to', 'its', 'roots', 'as', 'a', 'wild', ',', 'reckless', 'thrill', 'ride', '.', 'that', 'is', 'what', 'made', 'the', 'alien', 'series', 'so', 'popular', 'in', 'the', 'first', 'place', ',', 'and', 'that', 'is', 'what', 'will', 'keep', 'the', 'series', 'popular', 'in', 'any', 'future', 'installments', '.'], 'pos')\n"
     ]
    }
   ],
   "source": [
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "\n",
      "\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))\n",
    "print(\"\\n\")\n",
    "print(all_words[\"stupid\"]) # We see that more common words a, the, ., and others like given down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:3000]\n",
    "# only with now a new variable, word_features, which contains the top 3,000 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saunders', 'drunkenness', 'luggage', 'nevers', 'failed']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting words to Features with NLTK\n",
    "\n",
    "Here we are compiling feature lists of words from positive reviews and words from the negative reviews to hopefully see trends in specific types of words in positive or negative reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will find these top 3,000 words in our positive and negative documents, marking their \n",
    "# presence as either positive or negative:\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}              # Here features is a dictionary with keys = w and value as True / False\n",
    "    for w in word_features:    # Depending whether or not that word appears in the document\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can do this for all of our documents, saving the feature existence booleans and their respective positive or negative categories by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ambient': False, 'nevers': False, 'failed': False, 'rammed': False, 'stinky': False, 'ne': False, 'bloc': False, 'panaro': False, 'fiving': False, 'exemplary': False, 'bene': False, 'urges': False, 'belonging': False, 'apprehensive': False, 'meditating': False, 'congolese': False, 'broadens': False, 'fancies': False, 'luggage': False, 'hudlin': False, 'invested': False, 'cinematical': False, 'talent': False, 'afterword': False, 'nastiness': False, 'marci': False, 'greenway': False, 'prosperous': False, 'destined': False, 'smog': False, 'signifying': False, 'triumph': False, '1791': False, 'gurgle': False, 'birds': False, 'agreed': False, 'jeanne': False, 'seamless': False, 'consummated': False, 'l': False, 'sancho': False, 'cursed': False, 'cluding': False, 'slayings': False, 'brush': False, 'finnegan': False, 'tapestry': False, 'mazursky': False, '_54_': False, 'metamorphoses': False, 'jackhammer': False, 'projectioner': False, 'bargained': False, 'kathy': False, 'cyberpunk': False, 'line': True, 'cadillac': False, 'mask': False, 'alf': False, 'writes': False, 'fraction': False, 'unspeakable': False, 'spasmodic': False, 'dissipating': False, 'voluminous': False, 'relates': False, 'pot': False, 'unlike': False, 'upn': False, 'frees': False, 'mufti': False, 'sam': False, 'nonstop': False, 'blare': False, 'goldberg': False, 'sony': False, 'overshadowed': False, 'ulee': False, 'goof': False, 'paquin': False, 'canna': False, 'furnace': False, '2058': False, 'psyches': False, 'soused': False, 'scholarships': False, 'openings': False, 'badham': False, 'lite': False, 'daytrippers': False, 'interfere': False, 'paste': False, 'eeeewwwww': False, 'reanimator': False, 'maturation': False, 'northwestern': False, 'hyperbolic': False, 'throw': False, 'chivalry': False, 'jingo': False, 'insulin': False, 'training': False, 'shared': False, 'luchino': False, 'glengarry': False, 'flaccid': False, 'regroup': False, 'presently': False, '_is_': False, 'inhibit': False, 'awful': False, 'gotti': False, 'schticks': False, 'whiner': False, 'contender': False, 'excruciatingly': False, 'overruns': False, 'machette': False, 'beeps': False, 'consider': False, 'moulin': False, 'nodded': False, 'detractions': False, 'implausable': False, 'turkey': False, 'urban': False, 'reproduce': False, 'expressionistically': False, 'transpires': False, 'annabella': False, 'reactionary': False, 'flew': False, 'hormonal': False, 'tentacled': False, 'com': False, 'cholodenko': False, '_twice_': False, 'plagues': False, 'della': False, 'provincial': False, 'likeability': False, 'veering': False, 'hensley': False, 'foiled': False, 'paratroop': False, 'penchent': False, 'canoeing': False, 'inside': False, 'darby': False, 'theologians': False, 'noon': False, 'scrapping': False, 'validity': False, 'trailers': False, 'shadowing': False, 'clam': False, 'dimensions': False, 'noxema': False, 'fleeing': False, 'joann': False, 'performers': False, 'anyone': False, 'rousingly': False, 'biggest': True, 'delving': False, 'responsible': False, 'drops': False, 'showgirls': False, 'sermonize': False, 'aug': False, 'imhotep': False, 'pedagogical': False, 'manipulates': False, 'resists': False, 'valid': False, 'unicorns': False, 'telecommunications': False, 'cherie': False, 'indignities': False, 'emphasized': False, 'circumstance': False, 'fields': False, 'lughnasa': False, 'breakneck': False, 'unloving': False, 'finger': False, 'disaster': False, 'mesmerizing': False, 'evince': False, 'tweed': False, 'startrek': False, 'titshots': False, 'discussion': False, 'crouched': False, 'eisenhower': False, 'anabelle': False, 'behavious': False, 'charlie': False, 'bottoms': False, 'terrorizing': False, 'sleek': False, 'bartenders': False, 'grains': False, 'shoot': False, 'prolonged': False, 'speer': False, 'workaholics': False, 'beggining': False, 'paget': False, 'opinion': False, 'reference': False, 'gills': False, 'fasano': False, 'stingy': False, 'charact': False, 'oberon': False, 'systematically': False, 'les': False, 'dubarry': False, 'thicker': False, 'selflessly': False, 'unfair': False, 'average': False, 'new': True, 'tentatively': False, 'fooled': False, 'raja': False, 'issues': False, 'enjoyed': False, 'input': False, 'etat': False, 'deveu': False, 'estrangement': False, 'daviau': False, 'deathbed': False, 'liberating': False, 'wal': False, 'automatons': False, 'attests': False, 'blind': False, 'simulation': False, 'dispassionate': False, 'wore': False, 'midair': False, 'holdup': False, 'feather': False, 'beaming': False, 'vanish': False, 'blockbuster': False, 'overbearing': False, 'seasoned': False, 'side': False, 'suggests': False, 'cholera': False, 'aggravation': False, 'mushu': False, '_today_': False, 'later': False, 'situational': False, 'gatsby': False, 'draven': False, 'carrey': False, 'behaves': False, 'homophobe': False, 'unredeemable': False, 'bay': False, 'brill': False, 'approachment': False, 'parasitic': False, 'exclusively': False, 'baddeley': False, 'rope': False, 'meshes': False, 'fenced': False, 'flaws': False, 'aged': False, 'partying': False, 'gads': False, 'compassion': False, 'parillaud': False, 'dice': False, 'remedial': False, 'divulging': False, 'oiled': False, 'entombed': False, 'equalizes': False, 'benoit': False, 'surrounding': False, 'muslim': False, 'anally': False, 'begbie': False, 'lookin': False, 'coincidental': False, 'route': False, 'vilified': False, 'coasts': False, 'hands': False, 'norrington': False, 'incision': False, 'stalkers': False, 'scalvaging': False, 'happen': True, 'becomming': False, 'worf': False, 'directly': False, 'scorn': False, 'testimonials': False, 'humphry': False, 'covenant': False, 'ransom': False, 'barclay': False, 'uuuhhmmm': False, 'meditation': False, 'miami': False, 'noodles': False, 'will': False, 'pets': False, 'conduit': False, 'megabucks': False, 'litz': False, 'shepherd': False, 'sleep': False, 'building': False, 'downpour': False, 'silk': False, 'joaquin': False, 'food': False, 'bataillon': False, 'interpreter': False, 'colony': False, 'identifiers': False, 'etienne': False, 'knife': False, 'wilson': False, 'slap': False, 'admirer': False, 'sinks': False, 'stefanson': False, 'rko': False, 'frolicked': False, 'overflows': False, 'regales': False, 'revives': False, 'sela': False, 'alfonso': False, 'blessings': False, 'feelings': False, 'loudmouth': False, 'hold': False, 'montages': False, 'gnaw': False, 'personalized': False, 'ny': False, 'pearly': False, 'scripters': False, 'reproach': False, 'anand': False, 'mars': False, 'emotive': False, 'curmudgeons': False, 'bloodstains': False, 'dies': True, 'borscht': False, 'dunne': False, 'invokes': False, 'boobies': False, 'occupies': False, 'polanski': False, 'courted': False, '_fear_and_loathing_in_las_vegas_': False, 'fantasized': False, 'centerpieces': False, 'misteps': False, 'chunnel': False, 'aime': False, '_john': False, 'faye': False, 'pov': False, 'family': False, 'savior': False, 'bs': False, 'reload': False, 'limon': False, 'handily': False, 'valor': False, 'seems': True, 'brubaker': False, 'detritus': False, 'stained': False, 'omits': False, 'really': True, 'baffling': False, 'eckhart': False, 'tripp': False, 'gifford': False, 'cking': False, 'yankee': False, 'mocking': False, 'instructional': False, 'tip': False, 'bossy': False, 'mandrian': False, 'reeve': False, 'imitate': False, 'shoelaces': False, 'dallwitz': False, 'grizzled': False, 'tolerate': False, 'radiantly': False, 'crewmate': False, 'quits': False, 'morales': False, 'disinterested': False, 'gathering': False, 'wait': False, 'wainwright': False, 'cavorting': False, 'zaentz': False, 'destination': False, 'incident': False, 'emphasis': False, 'apothecary': False, 'revolutionaries': False, 'samaritan': False, 'eisenberg': False, 'butte': False, 'becuase': False, 'registered': False, 'accelerate': False, 'smits': False, 'pigeons': False, 'kai': False, 'knuckleheads': False, 'violinist': False, 'jock': False, 'rosebudd': False, 'soda': False, 'aura': False, 'sibling': False, 'unspool': False, 'schoolteacher': False, 'life': True, 'consultants': False, 'kareem': False, 'handyman': False, 'rudner': False, 'heals': False, 'brainerd': False, 'amity': False, '1847': False, 'lifespan': False, 'pammy': False, 'heaping': False, 'bound': False, 'repititive': False, 'challenge': False, 'unger': False, 'awarded': False, 'spiral': False, 'crassness': False, 'accented': False, 'nike': False, 'marilyn': False, 'tasteful': False, 'spoonful': False, 'dukas': False, 'meatloaf': False, 'coyotes': False, 'hospitable': False, 'lecherous': False, 'compose': False, 'stretched': False, 'tying': False, 'courts': False, 'overkill': False, 'employees': False, 'gelfling': False, 'scolding': False, 'antsy': False, 'deranged': False, 'hurry': False, 'alive': False, 'birkin': False, 'deflecting': False, 'extinction': False, 'bolton': False, 'caraciture': False, 'pastor': False, 'epitomizes': False, 'sorna': False, 'paunchy': False, 'fizzled': False, 'hardy': False, 'affability': False, 'bitterly': False, 'video': True, 'whirlpool': False, 'buildings': False, 'claudia': False, 'loathing': False, 'glorifies': False, 'snatchers': False, 'graceless': False, 'crams': False, 'luppi': False, 'schemer': False, 'replay': False, '_titanic_': False, 'blizzard': False, 'inept': False, 'appendaged': False, 'brawl': False, 'wrinkled': False, 'tightened': False, 'prints': False, 'entrances': False, 'hurlyburly': False, 'oevre': False, 'picky': False, 'degenerated': False, 'whorehouse': False, 'minimizing': False, 'drives': False, 'hygienists': False, 'tweaked': False, 'brigantine': False, 'await': False, 'guiler': False, 'decapitations': False, 'culp': False, 'floored': False, 'mayhew': False, 'disapprobation': False, 'sixties': False, 'severe': False, 'escaping': False, 'gisbourne': False, 'edna': False, 'jinx': False, 'opener': False, 'hasn': False, 'palms': False, 'sentimentally': False, 'vagrants': False, 'colonists': False, 'olga': False, 'opponents': False, 'douchebag': False, '}': False, 'golly': False, 'rank': False, 'flares': False, 'unintelligble': False, 'insultingly': False, 'cassavetes': False, 'sprung': False, 'sue': False, 'zones': False, 'felony': False, '03': False, 'traumatizes': False, 'patched': False, 'maniacally': False, 'greedy': False, 'maureen': False, 'greenfingers': False, 'svengalian': False, 'suited': False, 'concoctions': False, 'bark': False, 'drank': False, 'cohort': False, 'pragmatic': False, 'garrison': False, 'engenders': False, 'heartbreaks': False, 'offspring': False, 'paralyzed': False, 'ones': False, 'daena': False, 'espouses': False, 'hail': False, 'quintessential': False, 'abject': False, 'norman': False, 'sommer': False, 'economized': False, 'unattainable': False, 'neighbours': False, 'ascaride': False, 'splish': False, 'teen': True, 'vibrancy': False, 'alba': False, 'crows': False, 'expected': False, 'criticizes': False, 'spineless': False, 'suffuse': False, 'pronouns': False, 'floris': False, 'feuer': False, 'ultramaterialistic': False, 'droll': False, 'sway': False, 'davison': False, 'vehicular': False, 'manchu': False, 'confederate': False, 'permanence': False, 'skulking': False, 'yelchin': False, 'placement': False, 'septien': False, 'lanky': False, 'pie': False, 'pensive': False, 'novikov': False, 'conservationist': False, 'clumsy': False, 'coding': False, 'unlikable': False, 'invigorate': False, 'fairchild': False, 'weapon': False, 'broadcasts': False, 'nowadays': False, 'improvisational': False, 'heywood': False, 'gooding': False, 'reheal': False, 'inaccurately': False, 'ssbas': False, 'marcia': False, 'goofiness': False, 'flippancy': False, 'investigations': False, 'dionna': False, 'diversity': False, 'giddily': False, 'annette': False, 'ronin': False, 'thrusting': False, 'agree': False, 'voyeuristic': False, 'room': False, 'perfected': False, 'super': False, 'absoloute': False, 'it_': False, 'knightdom': False, 'detects': False, 'constellation': False, 'rereleased': False, 'amazon': False, 'junior': False, 'dubuque': False, 'undertaken': False, 'pressure': False, 'evangelical': False, 'clothed': False, 'clunkiness': False, 'swanbeck': False, 'subverts': False, 'perf': False, 'feigns': False, 'lavishly': False, 'bottom': True, 'samba': False, 'theatens': False, 'fumbling': False, 'naysayers': False, 'vail': False, 'hanoi': False, 'sheltering': False, 'glow': False, 'dampened': False, 'expurgating': False, 'hairdos': False, 'sadder': False, 'basic': False, 'poisonous': False, 'pretend': False, 'educate': False, 'unethical': False, 'triumphant': False, 'crew': False, 'rustin': False, 'guitry': False, 'activity': False, 'prologues': False, 'gyrating': False, 'seventh': False, 'allowances': False, 'kirkpatrick': False, 'atkins': False, 'lighthearted': False, 'hugging': False, 'cashing': False, 'ties': False, 'focused': False, 'altering': False, 'shallows': False, 'junkie': False, 'disengaging': False, 'amuse': False, 'adhered': False, 'resuce': False, 'heightening': False, 'mousy': False, 'rationale': False, 'flamboyantly': False, 'boone': False, 'feingold': False, 'enigmatical': False, 'foodmart': False, 'merit': False, 'heartwarmers': False, 'witt': False, 'indirectly': False, 'limbs': False, 'albeit': False, 'murray': False, 'hatami': False, 'slips': False, 'pecan': False, 'bloody': False, 'patti': False, 'fireworks': False, 'exposed': False, 'hommage': False, 'keeve': False, 'knack': False, 'timex': False, 'telecommunicative': False, 'scum': False, 'incongruities': False, 'brinkford': False, 'overcoats': False, 'backwords': False, 'violation': False, 'alone': False, 'genus': False, 'notables': False, 'recent': False, 'disease': False, 'hurt': False, 'improbabilities': False, 'words': False, 'grove': False, 'speak': False, 'baddies': False, 'hunts': False, 'repetitious': False, 'morlocs': False, 'dominican': False, 'illuminati': False, 'emshwiller': False, 'foreshadowing': False, 'consciousness': False, 'wendkos': False, 'roache': False, 'islam': False, 'prehistoric': False, 'deprecating': False, 'expressed': False, 'josie': False, 'energetically': False, 'bombarding': False, 'surrenders': False, 'hushes': False, 'roast': False, 'overlooks': False, 'beforehand': False, 'unopposed': False, 'empowerment': False, 'reproduces': False, '_blade_': False, 'mosley': False, 'overrated': False, 'mean': True, 'landmarks': False, 'koans': False, 'intro': False, 'advancement': False, 'bujold': False, 'experess': False, 'deceptive': False, 'dishonest': False, 'urbaniak': False, 'balm': False, 'heretic': False, 'sappiness': False, 'neal': False, 'huxley': False, 'flaring': False, 'gabby': False, 'meld': False, 'photos': False, 'vehemently': False, 'quoted': False, 'heat': False, 'barrage': False, 'icons': False, 'austrian': False, 'tongue': False, 'matron': False, 'bankole': False, 'dolls': False, 'clawed': False, 'actualy': False, 'vcrs': False, 'masterson': False, 'tyrannical': False, 'lyrics': False, 'janitorial': False, 'huckster': False, 'brainy': False, 'gargantuan': False, 'brenda': False, 'strauss': False, 'receiver': False, 'hydrogen': False, '1hr': False, 'handheld': False, 'atmostpheric': False, 'adversary': False, 'unsatisfied': False, 'sciora': False, 'voracious': False, 'closely': False, 'chemical': False, 'tomei': False, 'krupa': False, 'dimensionally': False, 'topiary': False, 'helpfulness': False, 'skeptic': False, 'windy': False, 'novo': False, 'highlight': False, 'shwarzenegger': False, 'astonishment': False, 'watchdogs': False, 'drop': False, 'witherspoon': False, 'escalate': False, 'breakaway': False, 'torment': False, 'slimeball': False, 'cute': False, 'vitarelli': False, 'flatlining': False, 'enlightening': False, 'frantically': False, 'starship': False, 'adorning': False, 'carmen': False, 'nearest': False, 'accent': False, 'barntill': False, 'fleiss': False, 'panicked': False, 'fizzles': False, 'newer': False, 'clunker': False, 'scared': False, 'impersonator': False, 'mantegna': False, 'whack': False, '1692': False, 'merhi': False, 'cheesefest': False, 'causing': False, 'four': False, 'pornographic': False, 'mulroney': False, 'i': True, 'ized': False, 'shots': False, 'tm': False, 'iceberg': False, 'prevents': False, 'broker': False, 'maneuvers': False, 'cigars': False, 'costume': False, 'superceded': False, 'flowers': False, 'brings': False, 'mcclaine': False, 'about': True, 'assitance': False, 'missed': False, 'coloreds': False, 'blending': False, 'androginous': False, 'groups': False, 'brutal': False, 'began': False, 'gassing': False, 'segal': False, 'propoganda': False, 'portion': False, 'visuals': False, 'thoroughly': False, 'magic': False, 'morality': False, 'loverboy': False, 'opts': False, 'dallied': False, 'reconstruction': False, 'orders': False, 'regrets': False, 'baser': False, 'thousand': False, 'abolitionists': False, 'morneau': False, 'rereading': False, 'wyatt': False, 'belloq': False, 'marianna': False, 'sanders': False, 'write': True, 'simpithize': False, 'pad': False, 'cokehead': False, 'grace': False, 'backing': False, 'exist': False, 'delivering': False, 'loomed': False, 'sami': False, '9mm': False, 'sheldon': False, 'untamed': False, 'grays': False, 'essential': False, 'mckenna': False, 'acupuncture': False, 'corporation': False, 'dam': False, 'apply': False, 'clips': False, 'skipper': False, 'redemption': False, 'klebold': False, 'likes': False, 'soothe': False, 'brainiac': False, 'craze': False, 'frog': False, 'punching': False, 'funnyman': False, 'fetishist': False, 'rehearsed': False, 'rogue': False, 'burwell': False, 'debating': False, 'hitchhiker': False, 'spotting': False, 'grounds': False, 'kerrigan': False, 'vapid': False, 'rica': False, 'dullest': False, 'possession': False, 'croon': False, 'permits': False, 'constructive': False, 'mention': False, 'elaine': False, 'recommend': False, 'tobolowsky': False, 'looooooong': False, 'inducers': False, 'transitions': False, 'rings': False, 'shell': False, 'societal': False, 'target': False, '---': False, 'oracle': False, 'arid': False, 'guardia': False, 'dum': False, '449': False, '59': False, 'langenkamp': False, 'pg': False, 'frown': False, 'adrienne': False, 'rivka': False, 'tipped': False, 'judgement': False, 'east': False, 'pinup': False, 'filmy': False, 'podrace': False, 'unmatched': False, 'pitchfork': False, 'granddaughter': False, 'masterminding': False, 'protestant': False, 'kennedys': False, 'woolly': False, 'audi': False, 'amberlike': False, 'toughs': False, 'textbooks': False, 'beanfield': False, 'prolific': False, 'silvio': False, 'walter': False, 'metropolis': False, 'lfe': False, 'exxon': False, 'senators': False, 'perfunctory': False, 'leavins': False, 'infinite': False, 'cleansed': False, 'thou': False, 'wacked': False, 'skimps': False, 'ifans': False, 'colleges': False, 'merchant': False, 'boiling': False, 'awe': False, 'raged': False, 'parka': False, 'attatched': False, 'sherbedgia': False, 'utterly': False, 'tale': False, 'ick': False, 'poodle': False, 'loony': False, 'witchcraft': False, 'marius': False, 'prefacing': False, 'lifesaving': False, 'serials': False, 'pun': False, 'provocative': False, 'envies': False, 'heston': False, 'argonians': False, 'chucky': False, 'goats': False, 'shivery': False, 'uglies': False, 'eilbacher': False, 'depictions': False, 'smidgeon': False, 'thorougly': False, 'kaleidoscope': False, 'renfo': False, 'donat': False, 'resemble': False, 'conciseness': False, 'drawling': False, 'shouts': False, 'king': False, 'kellner': False, 'gittin': False, 'preferably': False, 'dahl': False, '60s': False, 'exuding': False, 'reminisces': False, 'bret': False, 'deceptively': False, 'inuit': False, 'eliminates': False, '45': False, 'notting': False, 'slams': False, 'bluesman': False, '1950': False, 'nicholsons': False, 'consoling': False, '1952': False, 'proceeder': False, 'ditzism': False, 'betrayed': False, 'propaganda': False, 'whippersnapper': False, 'according': False, 'fathers': False, 'believeable': False, 'chortled': False, 'borrow': False, 'foreseen': False, 'burglars': False, 'misguided': False, 'pronged': False, 'tediously': False, 'mild': False, 'times': False, 'jfk': False, 'spector': False, 'scoff': False, 'undergoes': False, '_scarface_': False, 'frederique': False, 'explored': False, 'camcorder': False, 'pub': False, 'landmark': False, 'uli': False, 'mistrust': False, 'strengthens': False, 'costuming': False, 'pressed': False, 'purgatory': False, 'burkhart': False, 'lunges': False, 'figueras': False, 'aronov': False, 'fingernails': False, 'ah': False, 'chalkboard': False, 'grubby': False, 'schooled': False, 'convert': False, 'gracie': False, 'invlove': False, 'seizes': False, 'calling': False, 'cheapens': False, 'inspite': False, 'say': False, 'bookie': False, 'artistic': False, 'softhearted': False, 'chatter': False, 'suvari': False, 'workman': False, 'chester': False, 'mozzell': False, 'bullshit': False, 'fanged': False, 'strangely': False, 'accompanying': False, 'quashed': False, 'ambushes': False, 'shore': False, 'nine': False, 'sonorra': False, 'jam': False, 'gevedon': False, 'imaginable': False, 'freaks': False, 'neon': False, 'rectified': False, 'tidy': False, 'spectrum': False, 'ghibli': False, 'jolt': False, 'hypothesis': False, 'snodgress': False, 'bystander': False, 'illusion': False, 'passing': False, 'admittance': False, 'inheriting': False, 'debra': False, 'slaves': False, 'immortals': False, 'outstripped': False, 'tiegs': False, 'inky': False, 'evocative': False, 'grimaces': False, 'recognisable': False, 'truths': False, 'choke': False, 'prostitute': False, 'caption': False, 'categorized': False, 'sweetheart': False, 'farfetched': False, 'barstool': False, 'customer': False, 'credited': False, '>': False, 'playstation': False, 'pools': False, 'jillian': False, 'charter': False, 'detox': False, 'oafish': False, 'scriptwriting': False, 'amoeba': False, 'seminary': False, 'robespierre': False, 'tugboat': False, 'lyn': False, 'simulate': False, 'eavesdropping': False, 'epiphanies': False, 'beetlejuice': False, 'nephew': False, 'equate': False, 'mixture': False, '_la': False, '_does_': False, 'neater': False, 'cheatin': False, 'concerning': False, 'hingle': False, 'twas': False, 'earns': False, 'turnabout': False, 'luhrman': False, 'ought': False, 'dennis': False, 'exquisite': False, 'billowy': False, 'performed': False, 'ovens': False, 'arezzo': False, 'yanked': False, 'turtles': False, 'hobbes': False, 'lusty': False, 'eve': False, 'misbehavers': False, 'mental': False, 'gibson': False, 'wlodkowski': False, 'humane': False, 'dad': False, 'lau': False, 'grin': False, '_patlabor_': False, 'budget': False, 'valencia': False, 'artistically': False, 'andree': False, 'barrels': False, 'prosecuted': False, 'botulism': False, 'damn': False, 'cat': False, 'javert': False, 'telegraphing': False, 'intelligently': False, 'arrived': False, 'interested': False, 'lay': False, 'deciding': False, 'seder': False, 'peak': False, 'hindus': False, 'protecting': False, 'newcomers': False, 'frosty': False, 'brazillian': False, 'patently': False, 'argue': False, 'reassuring': False, 'levitch': False, 'internally': False, 'engage': False, 'enormous': False, 'xerox': False, 'guillaume': False, 'stupefied': False, 'slum': False, 'hogan': False, 'prized': False, 'gasp': False, 'england': False, 'divides': False, 'doctor': False, 'wolves': False, 'turrets': False, 'mtv': False, 'troma': False, 'damed': False, 'buliwyf': False, 'dolph': False, 'pastures': False, 'hannigan': False, 'rhodes': False, 'rugby': False, 'menacing': False, 'creek': False, 'tit': False, 'key': False, 'continue': False, 'absolutist': False, 'blackburn': False, 'firing': False, 'sixteen': False, 'faylen': False, 'easiest': False, 'shrew': False, 'airplay': False, 'yellows': False, 'enveloped': False, 'depalma': False, 'museums': False, 'law': False, 'propelled': False, 'wordsmith': False, 'appreciable': False, 'contemplating': False, 'distressed': False, 'acrimony': False, 'nausea': False, 'slinking': False, 'catharsis': False, 'played': False, 'thunderstorms': False, 'remi': False, 'silents': False, 'distances': False, 'elderly': False, 'overworking': False, 'judicious': False, 'bloodlines': False, '121': False, 'kimba': False, 'baptizes': False, 'bogglingly': False, 'confirm': False, 'besieged': False, 'kroon': False, 'unauthorized': False, 'felicity': False, 'colour': False, 'reined': False, 'mountainside': False, 'prescient': False, 'bubble': False, 'herc': False, 'rearrange': False, 'whooshed': False, 'seamlessly': False, 'invaded': False, 'interruptions': False, 'enabled': False, 'grieco': False, '426': False, 'regicide': False, 'please': False, 'headquarters': False, 'wickedly': False, 'armored': False, 'incompetently': False, 'epinions': False, 'storagehouse': False, 'fame': False, 'indignant': False, 'saunders': False, 'sauce': False, 'dumbass': False, 'gandolfini': False, 'mutually': False, 'krays': False, 'spotlights': False, 'ted': False, 'brauvara': False, 'gadgetry': False, 'poppa': False, 'counterexample': False, 'pursuit': False, 'insights': False, 'stare': False, 'lakeside': False, 'transpose': False, 'pfieffer': False, 'kitchen': False, 'muddling': False, 'angering': False, 'glenn': False, 'crap': False, 'hermetic': False, 'stymied': False, 'wavering': False, 'galaxy': False, 'lag': False, 'section': False, 'coolness': False, 'crawling': False, 'sommers': False, 'housekeeping': False, 'hugely': False, '_onegin_': False, 'palookaville': False, 'meloncholy': False, 'marcellus': False, 'bishops': False, 'bartellemeo': False, 'disposing': False, '_pick_chucky_up_': False, 'indigestible': False, 'enact': False, 'playacting': False, 'goals': False, 'mergers': False, 'criterion': False, 'noxzema': False, 'trees': False, 'starsystem': False, 'sublimated': False, 'jogging': False, 'embarassed': False, 'smugness': False, 'kickstarting': False, 'matches': False, 'kurt': False, 'crumpled': False, 'steadfast': False, 'yost': False, 'carreer': False, 'rasslin': False, 'turboman': False, 'guests': False, 'navarro': False, 'sheik': False, 'futures': False, 'user': False, 'mancini': False, 'robinson': False, 'mickelberry': False, 'slam': False, 'colon': False, 'snipping': False, 'tolls': False, 'passions': False, 'underdogs': False, 'homes': False, 'alienbusting': False, 'pictorial': False, 'toxic': False, 'meteoric': False, 'hose': False, 'durham': False, 'oddest': False, 'proficiency': False, 'suspicions': False, 'indoor': False, 'mazzello': False, 'withstand': False, 'joy': False, 'charms': False, 'balls': False, 'chills': False, 'naboo': False, 'rests': False, 'bmw': False, 'rein': False, 'cottage': False, 'choice': False, 'bored': False, 'grosser': False, 'josh': False, 'nicjolson': False, 'sequels': False, 'koren': False, 'porpoises': False, 'truism': False, 'seesaws': False, 'blurry': False, 'further': True, 'warmer': False, 'bracken': False, 'avrech': False, 'motorbike': False, 'pilgrim': False, 'mandible': False, 'stodge': False, 'amulet': False, 'myself': False, 'uninvolving': False, '2020': False, 'enlivens': False, 'elastica': False, 'hierarchy': False, 'deploy': False, 'halperin': False, 'bedsprings': False, 'saber': False, 'storm': False, 'inklings': False, '69': False, 'inexperience': False, 'stinker': False, 'scientists': False, 'leatherface': False, 'largely': False, 'serb': False, 'tiering': False, 'md': False, 'karate': False, '1885': False, 'gymnasium': False, 'perado': False, 'thunderous': False, 'booked': False, 'hires': False, 'arraki': False, 'philandering': False, 'mouseketeer': False, 'emasculated': False, 'playhouse': False, 'scouting': False, 'suggesting': False, 'throws': False, 'subtle': False, 'catacombs': False, 'tuck': False, 'mortals': False, 'inebriated': False, 'shannon': False, 'gorgeous': False, 'trapper': False, 'ryan_': False, 'sarita': False, 'doherty': False, 'spearing': False, 'complications': False, 'revolting': False, 'aris': False, 'readable': False, 'piousness': False, 'tsai': False, 'reporters': False, 'deadly': False, 'requiring': False, 'commences': False, 'pow': False, 'barby': False, 'schizophrenic': False, 'aboriginals': False, 'newark': False, 'cooly': False, 'embarrassing': False, 'cafes': False, 'avid': False, 'overdone': False, 'screwing': False, 'noisy': False, 'bathrobe': False, 'wallop': False, 'lakes': False, 'dumb': False, 'truely': False, 'distinguishing': False, 'bioport': False, 'crock': False, 'cyrus': False, 'state': False, 'cutlery': False, 'detractors': False, 'transcended': False, 'reminded': False, 'hematologist': False, 'hypnotised': False, 'conquistador': False, 'confederation': False, 'fuhrer': False, 'hotels': False, 'recording': False, 'loca': False, 'standards': False, 'blacksmith': False, 'cuz': False, 'poetry': False, 'unncessary': False, 'gusto': False, 'grocers': False, 'dramas': False, 'touching': False, 'kutcher': False, 'swartzenegger': False, 'industry': False, 'shoes': False, 'disappearance': False, 'metamorphosizes': False, 'ferrara': False, 'harpoons': False, 'soaked': False, 'sneers': False, 'wrenched': False, 'appetizer': False, 'aluminium': False, 'breakout': False, 'proposition': False, 'patches': False, 'wilted': False, 'advocates': False, 'assness': False, 'alienate': False, 'somethine': False, 'hones': False, 'obsessive': False, 'suceeds': False, 'precautions': False, 'brannagh': False, 'capsule': False, 'untrusting': False, 'airheads': False, 'flashback': False, 'boaz': False, 'backers': False, 'ideal': False, 'helene': False, 'harmed': False, 'breaching': False, 'mercifully': False, 'immortality': False, 'enticed': False, 'procreation': False, 'liane': False, 'dullsville': False, 'goodman': False, 'devilish': False, 'poitier': False, 'sorority': False, 'playfully': False, 'outgun': False, 'dodges': False, 'militant': False, 'sharman': False, 'testaments': False, 'ordeals': False, 'northen': False, 'crossover': False, 'allegiance': False, 'burrito': False, 'crystal': False, 'substances': False, 'court': False, '10b': False, 'crapper': False, 'raucous': False, 'jeb': False, '_dancing_': False, 'emax': False, 'casts': False, 'calvinistic': False, 'jenny': False, 'reconsider': False, 'arch': False, 'yawning': False, 'sulkis': False, 'tracked': False, 'flack': False, 'onatopp': False, 'll': False, 'hendrix': False, 'rio': False, 'muders': False, 'floop': False, 'flamboyance': False, 'rotunno': False, 'denizen': False, 'lillian': False, 'bibb': False, 'walled': False, 'miley': False, 'rashomon': False, 'girl': False, 'columnist': False, 'claiming': False, 'replenishing': False, 'decently': False, 'doses': False, 'manhatten': False, 'richman': False, 'gassed': False, 'theater': False, 'engulfed': False, 'patience': False, 'dohlen': False, 'shudder': False, 'venice': False, 'hy': False, 'jinn': False, '5000': False, 'seventeenth': False, 'hammiest': False, 'retrieving': False, 'fashioned': False, 'cockroaches': False, 'featuring': False, 'resting': False, 'expertise': False, 'vinny': False, 'truck': False, 'tonya': False, 'spurgeon': False, '8th': False, 'tries': False, 'empathy': False, 'youngers': False, 'cowboys': False, 'pulman': False, 'drills': False, 'disadvantage': False, 'garry': False, 'spoons': False, 'through': False, 'minds': False, 'unfinished': False, 'matched': False, 'filler': False, 'lasts': False, 'obligingly': False, 'advocated': False, 'chases': False, 'strangling': False, 'videotape': False, 'arty': False, 'advancements': False, 'smoked': False, 'swedish': False, 'professionals': False, 'denise': False, 'fl': False, 'unexpecting': False, 'received': False, 'clients': False, 'merrill': False, 'iwai': False, 'pedestal': False, 'drift': False, 'sigel': False, 'kaczynski': False, 'uninterrupted': False, 'unlocked': False, 'willy': False, 'petey': False, 'mancina': False, '___': False, 'craig': False, 'estrogenic': False, 'hannibal': False, 'bleak': False, 'unusually': False, 'lawyers': False, 'sgoingonaroundhere': False, 'headly': False, 'donated': False, 'lams': False, 'nonfiction': False, 'derbies': False, 'terence': False, 'cavalry': False, 'franz': False, 'mallet': False, 'keats': False, 'kelly': False, 'coleman': False, 'eye': False, '1922': False, 'porter': False, 'copious': False, 'neglect': False, 'wham': False, 'mindy': False, 'corresponds': False, 'quibble': False, 'traffic': False, 'depardieu': False, 'dixie': False, 'daylights': False, 'bobby': False, 'stashed': False, 'predatory': False, 'pathos': False, 'glamorize': False, 'rebuffed': False, 'schoolmarm': False, 'layered': False, 'capably': False, 'rienzo': False, 'urgency': False, 'interloper': False, 'halting': False, 'tectonic': False, 'saddled': False, 'intensive': False, 'inevitably': False, 'hypnotism': False, 'wong': False, 'comfortably': False, 'vansihes': False, 'cord': False, 'bliss': False, 'melange': False, ']': False, 'obsessively': False, 'expressive': False, 'adorned': False, 'expending': False, 'whaley': False, 'dull': False, 'peploe': False, 'managing': False, 'enriching': False, 'dropper': False, 'calcium': False, 'buffalo': False, 'marceau': False, 'itself': False, 'panama': False, 'shan': False, 'unsure': False, 'waldo': False, 'interrogated': False, '04': False, 'muffin': False, 'cue': False, 'falseness': False, 'watershed': False, 'ro': False, 'varsity': False, 'hindering': False, 'rockin': False, 'rockefeller': False, 'encourages': False, 'beginners': False, 'web': False, 'killers': False, 'hitchhike': False, 'coverup': False, 'pullam': False, 'planet': False, 'desensitization': False, 'morsels': False, 'sybil': False, 'berenger': False, 'scant': False, 'loneliness': False, 'christine': False, 'passionate': False, 'flutter': False, 'unabated': False, 'breathtaking': False, 'nostromo': False, 'stumbling': False, 'chiseled': False, 'nutcase': False, 'mass': False, 'morrow': False, 'whereabouts': False, 'gives': False, 'philosophers': False, 'goodfellas': False, 'yesterday': False, 'baseless': False, 'including': False, 'subsist': False, 'taguchi': False, 'bombastically': False, 'stillness': False, 'jean': False, 'bravest': False, 'bioports': False, 'sodium': False, 'weekly': False, 'mcjob': False, 'peyton': False, 'epitome': False, 'privileges': False, 'uncharismatic': False, 'huggers': False, 'geologist': False, 'bateer': False, 'throaty': False, 'random': False, 'byrne': False, 'effectful': False, 'strategically': False, 'accountable': False, 'sniffs': False, 'expertly': False, 'repetitions': False, 'jacket': False, 'affront': False, 'jingoistic': False, 'disowned': False, 'id4': False, 'hilt': False, 'empires': False, '_loathe_': False, 'paint': False, 'repeated': False, 'protectionist': False, 'nyman': False, 'shopping': False, 'localized': False, 'barrie': False, 'scoopfuls': False, 'innovative': False, 'synopsis': False, 'addams': False, 'wasteful': False, 'unlock': False, 'dearth': False, 'relegating': False, 'foolery': False, 'duplicity': False, 'suspects': False, 'oh': True, 'waxing': False, 'pendel': False, 'scratching': False, 'drawn': False, 'deus': False, 'humanitarian': False, 'added': False, 'author': False, 'nick': False, 'chappelle': False, 'deserted': False, 'productions': False, 'prisoners': False, 'auditions': False, 'vile': False, 'acquittal': False, 'cozart': False, 'homeworld': False, 'bowfinger': False, 'potentially': False, 'tormentor': False, 'gators': False, 'lesnie': False, 'pathological': False, 'codename': False, 'salesmanship': False, 'dispatching': False, 'miniature': False, 'caro': False, 'handbook': False, 'sinfully': False, 'banji': False, 'tre': False, 'herlihy': False, 'radiant': False, 'nyc': False, 'kindred': False, 'howie': False, 'wuthering': False, 'pans': False, 'luigi': False, 'biebe': False, 'tailored': False, 'britisher': False, 'lifeforms': False, 'forgiving': False, 'fennyman': False, 'macho': False, 'newsletter': False, 'cruiser': False, 'audaciously': False, 'debuting': False, 'capano': False, 'microwave': False, 'blackface': False, 'cannibal': False, 'monastery': False, 'firefighter': False, 'granite': False, 'beach': False, 'rossum': False, 'kelsey': False, 'tug': False, 'harmlessly': False, 'walking': False, 'reigns': False, 'evolved': False, 'unearth': False, 'separated': False, 'fu': False, 'payrolls': False, 'bluish': False, 'sweepstakes': False, '70s': False, 'attained': False, 'duties': False, 'blairwitch': False, 'temporal': False, 'foodstuffs': False, 'underwhelmed': False, 'obscura': False, 'billionth': False, 'excruciating': False, 'bloodline': False, 'pureed': False, 'aristocrat': False, 'primary': False, 'wring': False, 'jenette': False, 'necesary': False, 'great': False, 'jekyll': False, 'renovation': False, 'elektra': False, 'eerily': False, 'wittier': False, '1962': False, 'macpherson': False, 'arguing': False, 'similarities': False, 'coburn': False, 'build': False, 'purging': False, 'guzzling': False, 'landowner': False, 'oise': False, 'counterattack': False, 'lanier': False, 'bouncing': False, 'disappointed': False, 'scully': False, 'charles': False, 'rowe': False, 'resembles': False, 'hanky': False, 'harassment': False, 'thieves': False, 'dollop': False, 'egyptians': False, 'stupidness': False, 'shelby': False, 'belinda': False, '140': False, 'gallup': False, 'mulholland': False, 'danson': False, 'fiancee': False, 'littered': False, 'binge': False, 'countrysides': False, 'mikael': False, 'khanijian': False, 'minnie': False, 'heroic': False, 'bureau': False, 'mottled': False, 'nazism': False, 'screened': False, 'footage': False, 'spooketeria': False, 'drummond': False, 'atrocity': False, '1998s': False, 'psychodramas': False, 'welcome': False, 'kay': False, 'opulent': False, 'folk': False, 'busying': False, 'controls': False, 'ghouls': False, '571': False, 'fly': False, 'boyfriend': False, 'impulse': False, 'copper': False, 'booster': False, 'clothesline': False, 'wcw': False, 'bitching': False, 'batter': False, 'have': True, 'saucers': False, 'watered': False, 'music': True, 'donato': False, 'buzzsaw': False, 'underlining': False, 'cbs': False, 'accustomed': False, 'adafarasin': False, 'reflections': False, 'tomlin': False, 'moron': False, 'nudie': False, 'hysterics': False, 'bottles': False, 'bumpers': False, 'posthumous': False, 'spellbound': False, 'dumping': False, 'panache': False, 'glickman': False, 'comanche': False, 'hendren': False, 'reccomended': False, 'glasses': False, 'spewed': False, 'obliterates': False, 'outnumber': False, 'meany': False, 'miserables': False, 'senitmental': False, 'matewan': False, 'rollin': False, 'charizard': False, 'dora': False, 'shah': False, 'schreiber': False, 'contemplates': False, 'encrypted': False, 'huy': False, 'pressured': False, 'bloomingdale': False, 'jerk': False, 'clause': False, 'patric': False, 'kinetic': False, 'theroux': False, 'sideline': False, 'signifcance': False, 'graders': False, 'shaves': False, 'egypt': False, 'languishing': False, 'deflower': False, 'romanticized': False, 'oneself': False, 'decayed': False, 'comparing': False, 'contested': False, 'tortured': False, 'beautifully': False, 'umpire': False, 'aryans': False, 'kevin': False, 'occaisional': False, 'unerotic': False, 'ironsides': False, 'demarkov': False, 'bastardizing': False, 'jive': False, 'departed': False, 'carjacking': False, 'highlighting': False, 'crying': False, 'realistic': False, 'healers': False, 'drawbridge': False, 'collected': False, 'gayheart': False, 'plane': False, 'christmastown': False, 'robbery': False, 'inserts': False, '230': False, 'squares': False, 'imperioli': False, 'reeking': False, 'verdant': False, '34th': False, 'nossiter': False, 'songwriter': False, 'schema': False, 'swope': False, 'concepts': False, 'impetus': False, 'spectacularly': False, 'jolted': False, 'dances': False, 'smacked': False, 'at': False, 'slumps': False, 'cheekbones': False, 'creaky': False, 'flamenco': False, 'talmud': False, 'over': True, 'psychobabble': False, 'ducts': False, 'keyed': False, 'builder': False, 'faceless': False, 'abandoning': False, 'seeked': False, '1600s': False, 'weighs': False, 'juxtaposes': False, 'convent': False, 'supplement': False, 'theresa': False, 'convicted': False, 'incalculable': False, 'laced': False, 'rocks': False, 'perched': False, 'regardless': False, 'projectionist': False, 'unthinking': False, 'barfing': False, 'attendance': False, 'hitman': False, 'stock': False, 'tuition': False, 'choudhury': False, 'reappear': False, 'credible': False, 'cohesion': False, 'velicorapters': False, 'muddle': False, 'dialects': False, 'crocodile': False, 'rapper': False, 'preparing': False, 'eriq': False, 'haliwell': False, 'dishonourable': False, 'fleder': False, 'hudreds': False, 'angelina': False, 'splittingly': False, 'impart': False, 'soderburgh': False, 'evacuated': False, 'goddess': False, 'blueprint': False, 'wyle': False, 'stamper': False, 'survival': False, 'renton': False, 'modesty': False, 'facets': False, 'officious': False, 'scrawling': False, 'contain': False, 'streisand': False, 'xin': False, 'penalty': False, 'uplifted': False, 'hilariously': False, 'livingrooms': False, 'slapstickness': False, 'krishnamma': False, 'penuries': False, 'deferrential': False, 'buoyant': False, 'otherworldly': False, 'graduated': False, 'conked': False, 'goldthwait': False, 'firmer': False, 'suspicion': False, 'ariel': False, 'thuroughly': False, 'cements': False, 'wilkinson': False, 'contended': False, 'delivered': False, 'feathers': False, 'perishes': False, 'fonzie': False, 'stephanie': False, 'hardly': False, 'downpours': False, 'flashily': False, 'cormack': False, 'ancestors': False, 'winning': False, 'leash': False, 'cousine': False, 'exorcist': False, 'adopting': False, 'dines': False, 'portrayal': False, 'doonesbury': False, 'dickens': False, 'critique': True, 'misperception': False, 'terrifies': False, 'dichotomous': False, 'steamy': False, 'markets': False, 'dispenses': False, 'instincts': False, 'behaving': False, 'satellites': False, 'tarveling': False, 'fulfills': False, 'el': False, 'impactful': False, 'biloxi': False, 'lockup': False, 'miraculously': False, 'deeper': False, 'crossed': False, 'me': True, 'history': False, 'privileged': False, 'ahn': False, 'dancefloor': False, ';': False, 'anxiety': False, 'inundation': False, 'giallo': False, 'legislation': False, 'document': False, 'drinks': False, 'feel': False, 'harrowing': False, 'lovelace': False, 'daunting': False, 'squabbles': False, 'ape': False, 'though': False, 'hatchets': False, 'hotshot': False, 'steeped': False, 'hughes': False, 'coppolas': False, 'withdrawn': False, 'phobia': False, 'erm': False, 'bounteous': False, 'styles': False, 'parties': False, 'pumped': False, 'brandi': False, 'procreating': False, 'surrealistic': False, 'overpowered': False, 'linguists': False, 'talkfest': False, 'discs': False, 'interrelate': False, 'exorcised': False, 'twists': False, 'banyon': False, 'amigos': False, 'struck': False, 'doubled': False, 'misfits': False, 'flatly': False, 'kaisa': False, 'tailing': False, 'extraterrestrial': False, 'emphasizes': False, 'coherent': False, 'alcoholics': False, 'prominent': False, 'failing': False, 'covering': False, 'lautrec': False, 'filmore': False, 'misunderstood': False, 'mackintosh': False, 'virginal': False, 'emira': False, 'gypsy': False, 'quebec': False, 'assemble': False, 'masculine': False, 'human': False, 'ohlmyer': False, 'levers': False, 'mutton': False, 'exalted': False, 'ruthless': False, 'themself': False, 'sith': False, 'creator': False, 'depraved': False, 'recouperating': False, 'structured': False, 'below': False, 'legwork': False, 'cordial': False, 'speeding': False, 'epic': False, 'schlumpy': False, 'grump': False, 'jax': False, 'recover': False, 'worrying': False, 'requested': False, 'dormies': False, 'incites': False, 'smary': False, 'unspeakably': False, 'ann': False, 'cushing': False, 'bacri': False, 'emphasising': False, 'chastised': False, 'sena': False, 'confidently': False, 'carrefour': False, 'irving': False, 'supermasochist': False, 'trends': False, 'strapless': False, 'shaving': False, 'drunkenly': False, 'learned': False, 'yellow': False, 'idio': False, 'amy': False, 'petter': False, 'choderlos': False, 'caustic': False, 'unmarried': False, 'scarlett': False, 'lopping': False, 'vodka': False, 'dismembering': False, 'seung': False, 'analogue': False, 'rhea': False, 'foundations': False, 'positronic': False, 'thanksgiving': False, 'whit': False, 'rushing': False, 'dylan': False, 'seduction': False, 'amadeus': False, 'targets': False, 'redhead': False, 'spoken': False, 'neidermeyer': False, 'sitter': False, 'marveled': False, 'irritating': False, 'unexperienced': False, 'crotchety20': False, 'nastiest': False, 'cityscape': False, 'organizes': False, 'advising': False, 'sublimeness': False, 'stub': False, 'quell': False, 'dependable': False, 'ulation': False, 'reptiles': False, 'spinning': False, 'rest': False, 'sprites': False, 'funding': False, 'fright': False, 'mettler': False, 'billboard': False, 'inferiority': False, 'maximal': False, 'centres': False, 'angered': False, 'fistfights': False, 'unrefined': False, 'posta': False, 'buff': False, 'down': True, 'ideology': False, 'hall': False, 'wither': False, 'referring': False, 'sociology': False, 'brandan': False, 'utilised': False, 'summit': False, '`': False, 'sked': False, 'patchwork': False, 'skateboarders': False, 'achiever': False, 'good': True, 'polishing': False, 'privet': False, 'traceable': False, 'isolationist': False, 'museum': False, 'stiff': False, 'liking': False, 'enclosed': False, 'syllables': False, 'sketched': False, 'fury': False, 'registers': False, 'glamorizes': False, 'angelic': False, 'sooooo': False, 'reservoir': False, 'attentive': False, 'trumping': False, 'belief': False, 'gamut': False, 'classmate': False, 'bellyaching': False, 'lust': False, 'valmont': False, 'baileys': False, 'debonair': False, 'escapism': False, 'anal': False, 'sgt': False, 'whirls': False, 'airing': False, 'shucking': False, 'rush': False, 'laertes': False, 'stampede': False, 'raided': False, 'kurtzman': False, 'delaware': False, 'vaccaro': False, 'conversing': False, 'kauffman': False, 'beautician': False, 'thieveing': False, 'proficient': False, 'disappears': False, 'reindeer': False, 'slew': False, 'amongst': False, 'silver': False, 'linda': False, 'pakistani': False, 'wine': False, 'grifters': False, 'dwelling': False, 'terminators': False, '1923': False, 'scot': False, 'subtitled': False, 'blot': False, 'horny': False, 'janet': False, 'claudio': False, 'protects': False, 'moll': False, 'long': False, 'joyful': False, 'nathaniel': False, 'slang': False, 'misgivings': False, 'fragile': False, 'chuckie': False, 'arachnid': False, 'barrier': False, 'oooooo': False, 'advises': False, 'heather': False, 'volcano': False, 'darius': False, 'feat': False, 'simplying': False, 'abyss': False, 'waspy': False, 'menaces': False, 'pescara': False, 'doves': False, 'moritz': False, 'violet': False, 'beings': False, 'corbett': False, 'chalderns': False, 'ellin': False, 'vc': False, 'theatrically': False, 'mister': False, 'didactic': False, 'lipstick': False, 'schumann': False, 'veil': False, 'drool': False, 'tuneful': False, 'moo': False, 'loft': False, 'antihero': False, 'niagra': False, 'stares': False, 'india': False, 'feverishly': False, 'tempo': False, 'correlated': False, 'perpetual': False, 'lambeau': False, 'wes': True, 'winnie': False, 'tribesmen': False, 'wanderlust': False, 'unbuttoning': False, 'mann': False, 'sensual': False, 'schwarz': False, 'trend': False, 'reigned': False, 'quentin': False, 'wesson': False, 'giants': False, 'glowering': False, 'waaaayyyyyy': False, 'arielle': False, 'dietz': False, 'reinspired': False, 'victoire': False, 'lang': False, 'riotous': False, 'vignette': False, 'saints': False, 'gil': False, 'buddha': False, 'shield': False, 'commandeering': False, 'ironing': False, 'mediterranean': False, 'mute': False, 'confronting': False, 'mirrored': False, 'boomy': False, 'witty': False, 'rhetoric': False, 'instigate': False, 'persists': False, 'calculations': False, 'latest': False, 'categorize': False, 'hanania': False, 'monoko': False, 'flynt': False, 'verite': False, 'hickam': False, 'railed': False, 'naville': False, 'pisken': False, 'uneasieness': False, 'outmaneuver': False, 'massironi': False, 'flaming': False, 'suitor': False, 'apprehension': False, 'stuffs': False, 'achilles': False, 'translator': False, 'jones': False, 'elmo': False, 'online': False, 'cockburn': False, 'sittings': False, 'implementing': False, 'footnote': False, 'synthesier': False, 'forebodings': False, 'ladybug': False, '1862': False, 'occassionally': False, 'pollination': False, 'warrant': False, 'drunkenness': False, 'cappie': False, 'mm': False, 'fingerprints': False, 'shpadoinkle': False, 'pear': False, 'suspeneful': False, 'wrack': False, 'temperamentally': False, 'molten': False, 'jeweler': False, 'decision': False, 'alberto': False, 'decorates': False, 'supercilious': False, 'rossi': False, 'transcending': False, 'barely': False, 'vampyre': False, 'oeuvre': False, 'had': False, 'christabella': False, 'greenbury': False, 'before': True, 'sinker': False, 'imam': False, 'shagadellic': False, 'romanctic': False, 'dourif': False, 'kasa': False, 'trepidations': False, 'polarized': False, 'tut': False, 'musn': False, 'dumpster': False, 'imax': False, 'radar': False, 'plotless': False, 'gangbanger': False, 'proof': False, 'noooo': False, 'pretender': False, 'biohazard': False, 'modulation': False, 'brrrrrrrrr': False, 'overemphasizing': False, 'harwood': False, 'rebuts': False, 'presses': False, 'rise': False, 'grotesqe': False, 'sammo': False, 'dulles': False, 'xenophobe': False, 'manipulating': False, 'slaparound': False, 'hugh': False, 'brute': False, 'dilemmas': False, 'millennia': False, 'act': False, 'dunks': False, 'natives': False, 'faison': False, 'forensics': False, 'videotaping': False, 'trite': False, 'mozambique': False, 'depreciated': False, 'hunks': False, 'polemic': False, 'omegahedron': False, 'megan': False, 'quilting': False, 'lanes': False, 'inventie': False, 'fashions': False, 'stravinsky': False, 'refrained': False, 'archenemies': False, 'layoff': False, 'razzmatazz': False, 'gambled': False, 'trese': False, 'sappiest': False, 'ovitz': False, 'predicate': False, 'thong': False, 'sppedboat': False, 'worshipping': False, 'germane': False, 'vicki': False, 'founder': False, 'censoring': False, 'orbiting': False, 'cheech': False, 'soavi': False, 'humpalot': False, 'stats': False, 'runied': False, 'brutish': False, 'blawp': False, 'kitsch': False, 'che': False, 'buren': False, 'gift': False, 'modelled': False, '_looks_': False, 'packer': False, 'propel': False, 'cycling': False, 'ferrari': False, '152': False, 'bitchie': False, 'plexus': False, 'saves': False, 'coroner': False, 'knockdown': False, 'kisses': False, 'sweathogs': False, 'dewitt': False, 'koji': False, 'immortalizing': False, 'totatly': False, 'cavernous': False, 'inclusion': False, 'hairline': False, 'burkettsville': False, 'wittedness': False, 'filters': False, 'phenomena': False, 'ideals': False, 'resources': False, 'greyer': False, 'sheperd': False, 'prof': False, 'hos': False, 'waterway': False, 'mucho': False, 'urbanite': False, 'hosted': False, 'slaughtered': False, 'substance': False, 'homeless': False, '_american_psycho_': False, 'figured': True, 'melvins': False, 'brood': False, 'perused': False, 'resigned': False, 'cufflinks': False, 'possessive': False, 'reverses': False, 'catapults': False, 'surrendering': False, 'changer': False, 'packaging': False, 'nsync': False, 'beg': False, 'wrecks': False, 'powder': False, 'gazers': False, 'faculty': False, 'desperatly': False, 'christy': False, 'inspector': False, 'pelvis': False, 'foredoomed': False, 'tomaso': False, 'table': False, 'pantyhose': False, 'obligated': False, 'casino': False, 'outstandingly': False, 'resurfacing': False, 'laughs': False, 'nyu': False, 'anecdotes': False, 'nicolo': False, 'grouped': False, 'correspondant': False, 'stone': False, 'pryor': False, 'deserving': False, 'bias': False, 'anthropologist': False, 'henpecked': False, 'ridiculity': False, 'gos': False, 'anguished': False, 'conning': False, 'counteract': False, 'pseudonym': False, 'greenwald': False, 'deceptions': False, 'furnishings': False, 'iconoclast': False, 'zilch': False, 'womanhood': False, 'codas': False, 'dealers': False, 'misunderstand': False, 'confound': False, 'motherlode': False, 'trembling': False, 'kiss': False, 'ocmic': False, 'footages': False, 'heberle': False, 'executives': False, 'loopiness': False, 'lawyerly': False, 'transgression': False, 'ike': False, 'dug': False, 'lightsaber': False, 'batallion': False, 'technobabble': False, 'backhanded': False, 'kio': False, 'jeff': False, 'gallant': False, 'maintain': False, 'unchangeable': False, 'seminal': False, 'loggia': False, 'dramatized': False, 'uploading': False, 'smarmy': False, 'piggy': False, 'surrandon': False, 'sulk': False, 'courtyards': False, 'mcgaw': False, 'candlelit': False, 'thurral': False, 'merian': False, 'electricity': False, 'subtely': False, 'scent': False, 'gobbling': False, 'raj': False, 'darting': False, 'legitimate': False, 'overalls': False, 'dreadlocks': False, 'oneders': False, 'strathairn': False, 'migrates': False, 'monopoly': False, 'greenwich': False, 'fiberglass': False, 'prejudge': False, 'smiths': False, 'property': False, 'saigon': False, 'relaxes': False, 'kincaid': False, 'reevaluation': False, 'fulcrum': False, 'selleck': False, 'eartha': False, 'photosensitivity': False, 'pedicure': False, 'balto': False, 'screwer': False, 'theses': False, 'talmudic': False, 'exit': False, 'koppelman': False, '1992': False, 'bladerunner': False, 'deepening': False, 'referenced': False, 'members': False, 'dispels': False, 'humans': False, 'gwynne': False, 'gaerity': False, 'seldon': False, 'truckloads': False, 'sanctity': False, 'nirto': False, 'scuffle': False, 'madeliene': False, 'piotr': False, 'postmodern': False, 'uninviting': False, 'shrills': False, 'lesra': False, 'blackening': False, 'giacomo': False, 'coin': False, 'discourteous': False, 'uproar': False, '92t': False, 'irrationality': False, 'engrosses': False, 'discovering': False, 'scattering': False, 'skyler': False, 'noctis': False, 'wed': False, 'prided': False, 'infra': False, 'fuckin': False, 'creating': False, 'pzoniaks': False, 'pursuer': False, 'maryann': False, 'reconciling': False, 'amen': False, 'alters': False, 'panamanian': False, 'hagman': False, 'slavery': False, 'falzone': False, 'webcams': False, 'occuring': False, 'needle': False, 'straddle': False, 'boomer': False, 'macallister': False, 'franks': False, 'overdose': False, 'gopher': False, 'oft': False, 'corral': False, 'motorized': False, 'creamy': False, 'bvoice': False, 'abs': False, 'deciple': False, 'leathery': False, 'enlisting': False, 'wendell': False, 'emissary': False, 'ellicited': False, 'zinnemman': False, 'landord': False, 'fibrosis': False, 'shostakovich': False}\n"
     ]
    }
   ],
   "source": [
    "print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "# Awesome, now that we have our features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ambient': False,\n",
       "  'nevers': False,\n",
       "  'failed': False,\n",
       "  'rammed': False,\n",
       "  'stinky': False,\n",
       "  'ne': False,\n",
       "  'bloc': False,\n",
       "  'panaro': False,\n",
       "  'fiving': False,\n",
       "  'exemplary': False,\n",
       "  'bene': False,\n",
       "  'urges': False,\n",
       "  'belonging': False,\n",
       "  'apprehensive': False,\n",
       "  'meditating': False,\n",
       "  'congolese': False,\n",
       "  'broadens': False,\n",
       "  'fancies': False,\n",
       "  'luggage': False,\n",
       "  'hudlin': False,\n",
       "  'invested': False,\n",
       "  'cinematical': False,\n",
       "  'talent': False,\n",
       "  'afterword': False,\n",
       "  'nastiness': False,\n",
       "  'marci': False,\n",
       "  'greenway': False,\n",
       "  'prosperous': False,\n",
       "  'destined': False,\n",
       "  'smog': False,\n",
       "  'signifying': False,\n",
       "  'triumph': False,\n",
       "  '1791': False,\n",
       "  'gurgle': False,\n",
       "  'birds': False,\n",
       "  'agreed': False,\n",
       "  'jeanne': False,\n",
       "  'seamless': False,\n",
       "  'consummated': False,\n",
       "  'l': False,\n",
       "  'sancho': False,\n",
       "  'cursed': False,\n",
       "  'cluding': False,\n",
       "  'slayings': False,\n",
       "  'brush': False,\n",
       "  'finnegan': False,\n",
       "  'tapestry': False,\n",
       "  'mazursky': False,\n",
       "  '_54_': False,\n",
       "  'metamorphoses': False,\n",
       "  'jackhammer': False,\n",
       "  'projectioner': False,\n",
       "  'bargained': False,\n",
       "  'kathy': False,\n",
       "  'cyberpunk': False,\n",
       "  'line': False,\n",
       "  'cadillac': False,\n",
       "  'mask': False,\n",
       "  'alf': False,\n",
       "  'writes': False,\n",
       "  'fraction': False,\n",
       "  'unspeakable': False,\n",
       "  'spasmodic': False,\n",
       "  'dissipating': False,\n",
       "  'voluminous': False,\n",
       "  'relates': False,\n",
       "  'pot': False,\n",
       "  'unlike': False,\n",
       "  'upn': False,\n",
       "  'frees': False,\n",
       "  'mufti': False,\n",
       "  'sam': False,\n",
       "  'nonstop': False,\n",
       "  'blare': False,\n",
       "  'goldberg': False,\n",
       "  'sony': False,\n",
       "  'overshadowed': False,\n",
       "  'ulee': False,\n",
       "  'goof': False,\n",
       "  'paquin': False,\n",
       "  'canna': False,\n",
       "  'furnace': False,\n",
       "  '2058': False,\n",
       "  'psyches': False,\n",
       "  'soused': False,\n",
       "  'scholarships': False,\n",
       "  'openings': False,\n",
       "  'badham': False,\n",
       "  'lite': False,\n",
       "  'daytrippers': False,\n",
       "  'interfere': False,\n",
       "  'paste': False,\n",
       "  'eeeewwwww': False,\n",
       "  'reanimator': False,\n",
       "  'maturation': False,\n",
       "  'northwestern': False,\n",
       "  'hyperbolic': False,\n",
       "  'throw': False,\n",
       "  'chivalry': False,\n",
       "  'jingo': False,\n",
       "  'insulin': False,\n",
       "  'training': False,\n",
       "  'shared': False,\n",
       "  'luchino': False,\n",
       "  'glengarry': False,\n",
       "  'flaccid': False,\n",
       "  'regroup': False,\n",
       "  'presently': False,\n",
       "  '_is_': False,\n",
       "  'inhibit': False,\n",
       "  'awful': False,\n",
       "  'gotti': False,\n",
       "  'schticks': False,\n",
       "  'whiner': False,\n",
       "  'contender': False,\n",
       "  'excruciatingly': False,\n",
       "  'overruns': False,\n",
       "  'machette': False,\n",
       "  'beeps': False,\n",
       "  'consider': False,\n",
       "  'moulin': False,\n",
       "  'nodded': False,\n",
       "  'detractions': False,\n",
       "  'implausable': False,\n",
       "  'turkey': False,\n",
       "  'urban': False,\n",
       "  'reproduce': False,\n",
       "  'expressionistically': False,\n",
       "  'transpires': False,\n",
       "  'annabella': False,\n",
       "  'reactionary': False,\n",
       "  'flew': False,\n",
       "  'hormonal': False,\n",
       "  'tentacled': False,\n",
       "  'com': False,\n",
       "  'cholodenko': False,\n",
       "  '_twice_': False,\n",
       "  'plagues': False,\n",
       "  'della': False,\n",
       "  'provincial': False,\n",
       "  'likeability': False,\n",
       "  'veering': False,\n",
       "  'hensley': False,\n",
       "  'foiled': False,\n",
       "  'paratroop': False,\n",
       "  'penchent': False,\n",
       "  'canoeing': False,\n",
       "  'inside': False,\n",
       "  'darby': False,\n",
       "  'theologians': False,\n",
       "  'noon': False,\n",
       "  'scrapping': False,\n",
       "  'validity': False,\n",
       "  'trailers': False,\n",
       "  'shadowing': False,\n",
       "  'clam': False,\n",
       "  'dimensions': False,\n",
       "  'noxema': False,\n",
       "  'fleeing': False,\n",
       "  'joann': False,\n",
       "  'performers': False,\n",
       "  'anyone': False,\n",
       "  'rousingly': False,\n",
       "  'biggest': False,\n",
       "  'delving': False,\n",
       "  'responsible': False,\n",
       "  'drops': False,\n",
       "  'showgirls': False,\n",
       "  'sermonize': False,\n",
       "  'aug': False,\n",
       "  'imhotep': False,\n",
       "  'pedagogical': False,\n",
       "  'manipulates': False,\n",
       "  'resists': False,\n",
       "  'valid': False,\n",
       "  'unicorns': False,\n",
       "  'telecommunications': False,\n",
       "  'cherie': False,\n",
       "  'indignities': False,\n",
       "  'emphasized': False,\n",
       "  'circumstance': False,\n",
       "  'fields': False,\n",
       "  'lughnasa': False,\n",
       "  'breakneck': False,\n",
       "  'unloving': False,\n",
       "  'finger': False,\n",
       "  'disaster': False,\n",
       "  'mesmerizing': False,\n",
       "  'evince': False,\n",
       "  'tweed': False,\n",
       "  'startrek': False,\n",
       "  'titshots': False,\n",
       "  'discussion': False,\n",
       "  'crouched': False,\n",
       "  'eisenhower': False,\n",
       "  'anabelle': False,\n",
       "  'behavious': False,\n",
       "  'charlie': False,\n",
       "  'bottoms': False,\n",
       "  'terrorizing': False,\n",
       "  'sleek': False,\n",
       "  'bartenders': False,\n",
       "  'grains': False,\n",
       "  'shoot': False,\n",
       "  'prolonged': False,\n",
       "  'speer': False,\n",
       "  'workaholics': False,\n",
       "  'beggining': False,\n",
       "  'paget': False,\n",
       "  'opinion': False,\n",
       "  'reference': False,\n",
       "  'gills': False,\n",
       "  'fasano': False,\n",
       "  'stingy': False,\n",
       "  'charact': False,\n",
       "  'oberon': False,\n",
       "  'systematically': False,\n",
       "  'les': False,\n",
       "  'dubarry': False,\n",
       "  'thicker': False,\n",
       "  'selflessly': False,\n",
       "  'unfair': False,\n",
       "  'average': False,\n",
       "  'new': True,\n",
       "  'tentatively': False,\n",
       "  'fooled': False,\n",
       "  'raja': False,\n",
       "  'issues': False,\n",
       "  'enjoyed': False,\n",
       "  'input': False,\n",
       "  'etat': False,\n",
       "  'deveu': False,\n",
       "  'estrangement': False,\n",
       "  'daviau': False,\n",
       "  'deathbed': False,\n",
       "  'liberating': False,\n",
       "  'wal': False,\n",
       "  'automatons': False,\n",
       "  'attests': False,\n",
       "  'blind': False,\n",
       "  'simulation': False,\n",
       "  'dispassionate': False,\n",
       "  'wore': False,\n",
       "  'midair': False,\n",
       "  'holdup': False,\n",
       "  'feather': False,\n",
       "  'beaming': False,\n",
       "  'vanish': False,\n",
       "  'blockbuster': False,\n",
       "  'overbearing': False,\n",
       "  'seasoned': False,\n",
       "  'side': False,\n",
       "  'suggests': False,\n",
       "  'cholera': False,\n",
       "  'aggravation': False,\n",
       "  'mushu': False,\n",
       "  '_today_': False,\n",
       "  'later': False,\n",
       "  'situational': False,\n",
       "  'gatsby': False,\n",
       "  'draven': False,\n",
       "  'carrey': False,\n",
       "  'behaves': False,\n",
       "  'homophobe': False,\n",
       "  'unredeemable': False,\n",
       "  'bay': False,\n",
       "  'brill': False,\n",
       "  'approachment': False,\n",
       "  'parasitic': False,\n",
       "  'exclusively': False,\n",
       "  'baddeley': False,\n",
       "  'rope': False,\n",
       "  'meshes': False,\n",
       "  'fenced': False,\n",
       "  'flaws': False,\n",
       "  'aged': False,\n",
       "  'partying': False,\n",
       "  'gads': False,\n",
       "  'compassion': False,\n",
       "  'parillaud': False,\n",
       "  'dice': False,\n",
       "  'remedial': False,\n",
       "  'divulging': False,\n",
       "  'oiled': False,\n",
       "  'entombed': False,\n",
       "  'equalizes': False,\n",
       "  'benoit': False,\n",
       "  'surrounding': False,\n",
       "  'muslim': False,\n",
       "  'anally': False,\n",
       "  'begbie': False,\n",
       "  'lookin': False,\n",
       "  'coincidental': False,\n",
       "  'route': False,\n",
       "  'vilified': False,\n",
       "  'coasts': False,\n",
       "  'hands': False,\n",
       "  'norrington': False,\n",
       "  'incision': False,\n",
       "  'stalkers': False,\n",
       "  'scalvaging': False,\n",
       "  'happen': False,\n",
       "  'becomming': False,\n",
       "  'worf': False,\n",
       "  'directly': True,\n",
       "  'scorn': False,\n",
       "  'testimonials': False,\n",
       "  'humphry': False,\n",
       "  'covenant': False,\n",
       "  'ransom': False,\n",
       "  'barclay': False,\n",
       "  'uuuhhmmm': False,\n",
       "  'meditation': False,\n",
       "  'miami': False,\n",
       "  'noodles': False,\n",
       "  'will': True,\n",
       "  'pets': False,\n",
       "  'conduit': False,\n",
       "  'megabucks': False,\n",
       "  'litz': False,\n",
       "  'shepherd': False,\n",
       "  'sleep': False,\n",
       "  'building': False,\n",
       "  'downpour': False,\n",
       "  'silk': False,\n",
       "  'joaquin': False,\n",
       "  'food': False,\n",
       "  'bataillon': False,\n",
       "  'interpreter': False,\n",
       "  'colony': False,\n",
       "  'identifiers': False,\n",
       "  'etienne': False,\n",
       "  'knife': False,\n",
       "  'wilson': False,\n",
       "  'slap': False,\n",
       "  'admirer': False,\n",
       "  'sinks': False,\n",
       "  'stefanson': False,\n",
       "  'rko': False,\n",
       "  'frolicked': False,\n",
       "  'overflows': False,\n",
       "  'regales': False,\n",
       "  'revives': False,\n",
       "  'sela': False,\n",
       "  'alfonso': False,\n",
       "  'blessings': False,\n",
       "  'feelings': False,\n",
       "  'loudmouth': False,\n",
       "  'hold': False,\n",
       "  'montages': False,\n",
       "  'gnaw': False,\n",
       "  'personalized': False,\n",
       "  'ny': False,\n",
       "  'pearly': False,\n",
       "  'scripters': False,\n",
       "  'reproach': False,\n",
       "  'anand': False,\n",
       "  'mars': False,\n",
       "  'emotive': False,\n",
       "  'curmudgeons': False,\n",
       "  'bloodstains': False,\n",
       "  'dies': False,\n",
       "  'borscht': False,\n",
       "  'dunne': False,\n",
       "  'invokes': False,\n",
       "  'boobies': False,\n",
       "  'occupies': False,\n",
       "  'polanski': False,\n",
       "  'courted': False,\n",
       "  '_fear_and_loathing_in_las_vegas_': False,\n",
       "  'fantasized': False,\n",
       "  'centerpieces': False,\n",
       "  'misteps': False,\n",
       "  'chunnel': False,\n",
       "  'aime': False,\n",
       "  '_john': False,\n",
       "  'faye': False,\n",
       "  'pov': False,\n",
       "  'family': False,\n",
       "  'savior': False,\n",
       "  'bs': False,\n",
       "  'reload': False,\n",
       "  'limon': False,\n",
       "  'handily': False,\n",
       "  'valor': False,\n",
       "  'seems': True,\n",
       "  'brubaker': False,\n",
       "  'detritus': False,\n",
       "  'stained': False,\n",
       "  'omits': False,\n",
       "  'really': False,\n",
       "  'baffling': False,\n",
       "  'eckhart': False,\n",
       "  'tripp': False,\n",
       "  'gifford': False,\n",
       "  'cking': False,\n",
       "  'yankee': False,\n",
       "  'mocking': False,\n",
       "  'instructional': False,\n",
       "  'tip': False,\n",
       "  'bossy': False,\n",
       "  'mandrian': False,\n",
       "  'reeve': False,\n",
       "  'imitate': False,\n",
       "  'shoelaces': False,\n",
       "  'dallwitz': False,\n",
       "  'grizzled': False,\n",
       "  'tolerate': False,\n",
       "  'radiantly': False,\n",
       "  'crewmate': False,\n",
       "  'quits': False,\n",
       "  'morales': False,\n",
       "  'disinterested': False,\n",
       "  'gathering': False,\n",
       "  'wait': False,\n",
       "  'wainwright': False,\n",
       "  'cavorting': False,\n",
       "  'zaentz': False,\n",
       "  'destination': False,\n",
       "  'incident': False,\n",
       "  'emphasis': False,\n",
       "  'apothecary': False,\n",
       "  'revolutionaries': False,\n",
       "  'samaritan': False,\n",
       "  'eisenberg': False,\n",
       "  'butte': False,\n",
       "  'becuase': False,\n",
       "  'registered': False,\n",
       "  'accelerate': False,\n",
       "  'smits': False,\n",
       "  'pigeons': False,\n",
       "  'kai': False,\n",
       "  'knuckleheads': False,\n",
       "  'violinist': False,\n",
       "  'jock': False,\n",
       "  'rosebudd': False,\n",
       "  'soda': False,\n",
       "  'aura': False,\n",
       "  'sibling': False,\n",
       "  'unspool': False,\n",
       "  'schoolteacher': False,\n",
       "  'life': True,\n",
       "  'consultants': False,\n",
       "  'kareem': False,\n",
       "  'handyman': False,\n",
       "  'rudner': False,\n",
       "  'heals': False,\n",
       "  'brainerd': False,\n",
       "  'amity': False,\n",
       "  '1847': False,\n",
       "  'lifespan': False,\n",
       "  'pammy': False,\n",
       "  'heaping': False,\n",
       "  'bound': False,\n",
       "  'repititive': False,\n",
       "  'challenge': False,\n",
       "  'unger': False,\n",
       "  'awarded': False,\n",
       "  'spiral': False,\n",
       "  'crassness': False,\n",
       "  'accented': False,\n",
       "  'nike': False,\n",
       "  'marilyn': False,\n",
       "  'tasteful': False,\n",
       "  'spoonful': False,\n",
       "  'dukas': False,\n",
       "  'meatloaf': False,\n",
       "  'coyotes': False,\n",
       "  'hospitable': False,\n",
       "  'lecherous': False,\n",
       "  'compose': False,\n",
       "  'stretched': False,\n",
       "  'tying': False,\n",
       "  'courts': False,\n",
       "  'overkill': False,\n",
       "  'employees': False,\n",
       "  'gelfling': False,\n",
       "  'scolding': False,\n",
       "  'antsy': False,\n",
       "  'deranged': False,\n",
       "  'hurry': False,\n",
       "  'alive': False,\n",
       "  'birkin': False,\n",
       "  'deflecting': False,\n",
       "  'extinction': False,\n",
       "  'bolton': False,\n",
       "  'caraciture': False,\n",
       "  'pastor': False,\n",
       "  'epitomizes': False,\n",
       "  'sorna': False,\n",
       "  'paunchy': False,\n",
       "  'fizzled': False,\n",
       "  'hardy': False,\n",
       "  'affability': False,\n",
       "  'bitterly': False,\n",
       "  'video': False,\n",
       "  'whirlpool': False,\n",
       "  'buildings': False,\n",
       "  'claudia': False,\n",
       "  'loathing': False,\n",
       "  'glorifies': False,\n",
       "  'snatchers': False,\n",
       "  'graceless': False,\n",
       "  'crams': False,\n",
       "  'luppi': False,\n",
       "  'schemer': False,\n",
       "  'replay': False,\n",
       "  '_titanic_': False,\n",
       "  'blizzard': False,\n",
       "  'inept': False,\n",
       "  'appendaged': False,\n",
       "  'brawl': False,\n",
       "  'wrinkled': False,\n",
       "  'tightened': False,\n",
       "  'prints': False,\n",
       "  'entrances': False,\n",
       "  'hurlyburly': False,\n",
       "  'oevre': False,\n",
       "  'picky': True,\n",
       "  'degenerated': False,\n",
       "  'whorehouse': False,\n",
       "  'minimizing': False,\n",
       "  'drives': False,\n",
       "  'hygienists': False,\n",
       "  'tweaked': False,\n",
       "  'brigantine': False,\n",
       "  'await': False,\n",
       "  'guiler': False,\n",
       "  'decapitations': False,\n",
       "  'culp': False,\n",
       "  'floored': False,\n",
       "  'mayhew': False,\n",
       "  'disapprobation': False,\n",
       "  'sixties': False,\n",
       "  'severe': False,\n",
       "  'escaping': False,\n",
       "  'gisbourne': False,\n",
       "  'edna': False,\n",
       "  'jinx': False,\n",
       "  'opener': False,\n",
       "  'hasn': False,\n",
       "  'palms': False,\n",
       "  'sentimentally': False,\n",
       "  'vagrants': False,\n",
       "  'colonists': False,\n",
       "  'olga': False,\n",
       "  'opponents': False,\n",
       "  'douchebag': False,\n",
       "  '}': False,\n",
       "  'golly': False,\n",
       "  'rank': False,\n",
       "  'flares': False,\n",
       "  'unintelligble': False,\n",
       "  'insultingly': False,\n",
       "  'cassavetes': False,\n",
       "  'sprung': False,\n",
       "  'sue': False,\n",
       "  'zones': False,\n",
       "  'felony': False,\n",
       "  '03': False,\n",
       "  'traumatizes': False,\n",
       "  'patched': False,\n",
       "  'maniacally': False,\n",
       "  'greedy': False,\n",
       "  'maureen': False,\n",
       "  'greenfingers': False,\n",
       "  'svengalian': False,\n",
       "  'suited': False,\n",
       "  'concoctions': False,\n",
       "  'bark': False,\n",
       "  'drank': False,\n",
       "  'cohort': False,\n",
       "  'pragmatic': False,\n",
       "  'garrison': False,\n",
       "  'engenders': False,\n",
       "  'heartbreaks': False,\n",
       "  'offspring': False,\n",
       "  'paralyzed': False,\n",
       "  'ones': False,\n",
       "  'daena': False,\n",
       "  'espouses': False,\n",
       "  'hail': False,\n",
       "  'quintessential': False,\n",
       "  'abject': False,\n",
       "  'norman': False,\n",
       "  'sommer': False,\n",
       "  'economized': False,\n",
       "  'unattainable': False,\n",
       "  'neighbours': False,\n",
       "  'ascaride': False,\n",
       "  'splish': False,\n",
       "  'teen': False,\n",
       "  'vibrancy': False,\n",
       "  'alba': False,\n",
       "  'crows': False,\n",
       "  'expected': False,\n",
       "  'criticizes': False,\n",
       "  'spineless': False,\n",
       "  'suffuse': False,\n",
       "  'pronouns': False,\n",
       "  'floris': False,\n",
       "  'feuer': False,\n",
       "  'ultramaterialistic': False,\n",
       "  'droll': False,\n",
       "  'sway': False,\n",
       "  'davison': False,\n",
       "  'vehicular': False,\n",
       "  'manchu': False,\n",
       "  'confederate': False,\n",
       "  'permanence': False,\n",
       "  'skulking': False,\n",
       "  'yelchin': False,\n",
       "  'placement': False,\n",
       "  'septien': False,\n",
       "  'lanky': False,\n",
       "  'pie': False,\n",
       "  'pensive': False,\n",
       "  'novikov': False,\n",
       "  'conservationist': False,\n",
       "  'clumsy': False,\n",
       "  'coding': False,\n",
       "  'unlikable': False,\n",
       "  'invigorate': False,\n",
       "  'fairchild': False,\n",
       "  'weapon': False,\n",
       "  'broadcasts': False,\n",
       "  'nowadays': False,\n",
       "  'improvisational': False,\n",
       "  'heywood': False,\n",
       "  'gooding': False,\n",
       "  'reheal': False,\n",
       "  'inaccurately': False,\n",
       "  'ssbas': False,\n",
       "  'marcia': False,\n",
       "  'goofiness': False,\n",
       "  'flippancy': False,\n",
       "  'investigations': False,\n",
       "  'dionna': False,\n",
       "  'diversity': False,\n",
       "  'giddily': False,\n",
       "  'annette': False,\n",
       "  'ronin': False,\n",
       "  'thrusting': False,\n",
       "  'agree': False,\n",
       "  'voyeuristic': False,\n",
       "  'room': False,\n",
       "  'perfected': False,\n",
       "  'super': False,\n",
       "  'absoloute': False,\n",
       "  'it_': False,\n",
       "  'knightdom': False,\n",
       "  'detects': False,\n",
       "  'constellation': False,\n",
       "  'rereleased': False,\n",
       "  'amazon': False,\n",
       "  'junior': False,\n",
       "  'dubuque': False,\n",
       "  'undertaken': False,\n",
       "  'pressure': False,\n",
       "  'evangelical': False,\n",
       "  'clothed': False,\n",
       "  'clunkiness': False,\n",
       "  'swanbeck': False,\n",
       "  'subverts': False,\n",
       "  'perf': False,\n",
       "  'feigns': False,\n",
       "  'lavishly': False,\n",
       "  'bottom': False,\n",
       "  'samba': False,\n",
       "  'theatens': False,\n",
       "  'fumbling': False,\n",
       "  'naysayers': False,\n",
       "  'vail': False,\n",
       "  'hanoi': False,\n",
       "  'sheltering': False,\n",
       "  'glow': False,\n",
       "  'dampened': False,\n",
       "  'expurgating': False,\n",
       "  'hairdos': False,\n",
       "  'sadder': False,\n",
       "  'basic': False,\n",
       "  'poisonous': False,\n",
       "  'pretend': False,\n",
       "  'educate': False,\n",
       "  'unethical': False,\n",
       "  'triumphant': False,\n",
       "  'crew': False,\n",
       "  'rustin': False,\n",
       "  'guitry': False,\n",
       "  'activity': False,\n",
       "  'prologues': False,\n",
       "  'gyrating': False,\n",
       "  'seventh': False,\n",
       "  'allowances': False,\n",
       "  'kirkpatrick': False,\n",
       "  'atkins': False,\n",
       "  'lighthearted': False,\n",
       "  'hugging': False,\n",
       "  'cashing': False,\n",
       "  'ties': False,\n",
       "  'focused': False,\n",
       "  'altering': False,\n",
       "  'shallows': False,\n",
       "  'junkie': False,\n",
       "  'disengaging': False,\n",
       "  'amuse': False,\n",
       "  'adhered': False,\n",
       "  'resuce': False,\n",
       "  'heightening': False,\n",
       "  'mousy': False,\n",
       "  'rationale': False,\n",
       "  'flamboyantly': False,\n",
       "  'boone': False,\n",
       "  'feingold': False,\n",
       "  'enigmatical': False,\n",
       "  'foodmart': False,\n",
       "  'merit': False,\n",
       "  'heartwarmers': False,\n",
       "  'witt': False,\n",
       "  'indirectly': False,\n",
       "  'limbs': False,\n",
       "  'albeit': False,\n",
       "  'murray': False,\n",
       "  'hatami': False,\n",
       "  'slips': False,\n",
       "  'pecan': False,\n",
       "  'bloody': False,\n",
       "  'patti': False,\n",
       "  'fireworks': False,\n",
       "  'exposed': False,\n",
       "  'hommage': False,\n",
       "  'keeve': False,\n",
       "  'knack': False,\n",
       "  'timex': False,\n",
       "  'telecommunicative': False,\n",
       "  'scum': False,\n",
       "  'incongruities': False,\n",
       "  'brinkford': False,\n",
       "  'overcoats': False,\n",
       "  'backwords': False,\n",
       "  'violation': False,\n",
       "  'alone': False,\n",
       "  'genus': False,\n",
       "  'notables': False,\n",
       "  'recent': False,\n",
       "  'disease': False,\n",
       "  'hurt': False,\n",
       "  'improbabilities': False,\n",
       "  'words': False,\n",
       "  'grove': False,\n",
       "  'speak': False,\n",
       "  'baddies': False,\n",
       "  'hunts': False,\n",
       "  'repetitious': False,\n",
       "  'morlocs': False,\n",
       "  'dominican': False,\n",
       "  'illuminati': False,\n",
       "  'emshwiller': False,\n",
       "  'foreshadowing': False,\n",
       "  'consciousness': False,\n",
       "  'wendkos': False,\n",
       "  'roache': False,\n",
       "  'islam': False,\n",
       "  'prehistoric': False,\n",
       "  'deprecating': False,\n",
       "  'expressed': False,\n",
       "  'josie': False,\n",
       "  'energetically': False,\n",
       "  'bombarding': False,\n",
       "  'surrenders': False,\n",
       "  'hushes': False,\n",
       "  'roast': False,\n",
       "  'overlooks': False,\n",
       "  'beforehand': False,\n",
       "  'unopposed': False,\n",
       "  'empowerment': False,\n",
       "  'reproduces': False,\n",
       "  '_blade_': False,\n",
       "  'mosley': False,\n",
       "  'overrated': False,\n",
       "  'mean': False,\n",
       "  'landmarks': False,\n",
       "  'koans': False,\n",
       "  'intro': False,\n",
       "  'advancement': False,\n",
       "  'bujold': False,\n",
       "  'experess': False,\n",
       "  'deceptive': False,\n",
       "  'dishonest': False,\n",
       "  'urbaniak': False,\n",
       "  'balm': False,\n",
       "  'heretic': False,\n",
       "  'sappiness': False,\n",
       "  'neal': False,\n",
       "  'huxley': False,\n",
       "  'flaring': False,\n",
       "  'gabby': False,\n",
       "  'meld': False,\n",
       "  'photos': False,\n",
       "  'vehemently': False,\n",
       "  'quoted': False,\n",
       "  'heat': False,\n",
       "  'barrage': False,\n",
       "  'icons': False,\n",
       "  'austrian': False,\n",
       "  'tongue': False,\n",
       "  'matron': False,\n",
       "  'bankole': False,\n",
       "  'dolls': False,\n",
       "  'clawed': False,\n",
       "  'actualy': False,\n",
       "  'vcrs': False,\n",
       "  'masterson': False,\n",
       "  'tyrannical': False,\n",
       "  'lyrics': False,\n",
       "  'janitorial': False,\n",
       "  'huckster': False,\n",
       "  'brainy': False,\n",
       "  'gargantuan': False,\n",
       "  'brenda': False,\n",
       "  'strauss': False,\n",
       "  'receiver': False,\n",
       "  'hydrogen': False,\n",
       "  '1hr': False,\n",
       "  'handheld': False,\n",
       "  'atmostpheric': False,\n",
       "  'adversary': False,\n",
       "  'unsatisfied': False,\n",
       "  'sciora': False,\n",
       "  'voracious': False,\n",
       "  'closely': False,\n",
       "  'chemical': False,\n",
       "  'tomei': False,\n",
       "  'krupa': False,\n",
       "  'dimensionally': False,\n",
       "  'topiary': False,\n",
       "  'helpfulness': False,\n",
       "  'skeptic': False,\n",
       "  'windy': False,\n",
       "  'novo': False,\n",
       "  'highlight': False,\n",
       "  'shwarzenegger': False,\n",
       "  'astonishment': False,\n",
       "  'watchdogs': False,\n",
       "  'drop': False,\n",
       "  'witherspoon': False,\n",
       "  'escalate': False,\n",
       "  'breakaway': False,\n",
       "  'torment': False,\n",
       "  'slimeball': False,\n",
       "  'cute': True,\n",
       "  'vitarelli': False,\n",
       "  'flatlining': False,\n",
       "  'enlightening': False,\n",
       "  'frantically': False,\n",
       "  'starship': False,\n",
       "  'adorning': False,\n",
       "  'carmen': False,\n",
       "  'nearest': False,\n",
       "  'accent': False,\n",
       "  'barntill': False,\n",
       "  'fleiss': False,\n",
       "  'panicked': False,\n",
       "  'fizzles': False,\n",
       "  'newer': False,\n",
       "  'clunker': False,\n",
       "  'scared': False,\n",
       "  'impersonator': False,\n",
       "  'mantegna': False,\n",
       "  'whack': False,\n",
       "  '1692': False,\n",
       "  'merhi': False,\n",
       "  'cheesefest': False,\n",
       "  'causing': False,\n",
       "  'four': False,\n",
       "  'pornographic': False,\n",
       "  'mulroney': False,\n",
       "  'i': False,\n",
       "  'ized': False,\n",
       "  'shots': False,\n",
       "  'tm': False,\n",
       "  'iceberg': False,\n",
       "  'prevents': False,\n",
       "  'broker': False,\n",
       "  'maneuvers': False,\n",
       "  'cigars': False,\n",
       "  'costume': False,\n",
       "  'superceded': False,\n",
       "  'flowers': False,\n",
       "  'brings': False,\n",
       "  'mcclaine': False,\n",
       "  'about': False,\n",
       "  'assitance': False,\n",
       "  'missed': False,\n",
       "  'coloreds': False,\n",
       "  'blending': False,\n",
       "  'androginous': False,\n",
       "  'groups': False,\n",
       "  'brutal': False,\n",
       "  'began': False,\n",
       "  'gassing': False,\n",
       "  'segal': False,\n",
       "  'propoganda': False,\n",
       "  'portion': False,\n",
       "  'visuals': False,\n",
       "  'thoroughly': False,\n",
       "  'magic': False,\n",
       "  'morality': False,\n",
       "  'loverboy': False,\n",
       "  'opts': False,\n",
       "  'dallied': False,\n",
       "  'reconstruction': False,\n",
       "  'orders': False,\n",
       "  'regrets': False,\n",
       "  'baser': False,\n",
       "  'thousand': False,\n",
       "  'abolitionists': False,\n",
       "  'morneau': False,\n",
       "  'rereading': False,\n",
       "  'wyatt': False,\n",
       "  'belloq': False,\n",
       "  'marianna': False,\n",
       "  'sanders': False,\n",
       "  'write': False,\n",
       "  'simpithize': False,\n",
       "  'pad': False,\n",
       "  'cokehead': False,\n",
       "  'grace': False,\n",
       "  'backing': False,\n",
       "  'exist': False,\n",
       "  'delivering': False,\n",
       "  'loomed': False,\n",
       "  'sami': False,\n",
       "  '9mm': False,\n",
       "  'sheldon': False,\n",
       "  'untamed': False,\n",
       "  'grays': False,\n",
       "  'essential': False,\n",
       "  'mckenna': False,\n",
       "  'acupuncture': False,\n",
       "  'corporation': False,\n",
       "  'dam': False,\n",
       "  'apply': False,\n",
       "  'clips': False,\n",
       "  'skipper': False,\n",
       "  'redemption': False,\n",
       "  'klebold': False,\n",
       "  'likes': False,\n",
       "  'soothe': False,\n",
       "  'brainiac': False,\n",
       "  'craze': False,\n",
       "  'frog': False,\n",
       "  'punching': False,\n",
       "  'funnyman': False,\n",
       "  'fetishist': False,\n",
       "  'rehearsed': False,\n",
       "  'rogue': False,\n",
       "  'burwell': False,\n",
       "  'debating': False,\n",
       "  'hitchhiker': False,\n",
       "  'spotting': False,\n",
       "  'grounds': False,\n",
       "  'kerrigan': False,\n",
       "  'vapid': False,\n",
       "  'rica': False,\n",
       "  'dullest': False,\n",
       "  'possession': False,\n",
       "  'croon': False,\n",
       "  'permits': False,\n",
       "  'constructive': False,\n",
       "  'mention': False,\n",
       "  'elaine': False,\n",
       "  'recommend': False,\n",
       "  'tobolowsky': False,\n",
       "  'looooooong': False,\n",
       "  'inducers': False,\n",
       "  'transitions': False,\n",
       "  'rings': False,\n",
       "  'shell': False,\n",
       "  'societal': False,\n",
       "  'target': False,\n",
       "  '---': False,\n",
       "  'oracle': False,\n",
       "  'arid': False,\n",
       "  'guardia': False,\n",
       "  'dum': False,\n",
       "  '449': False,\n",
       "  '59': False,\n",
       "  'langenkamp': False,\n",
       "  'pg': False,\n",
       "  'frown': False,\n",
       "  'adrienne': False,\n",
       "  'rivka': False,\n",
       "  'tipped': False,\n",
       "  'judgement': False,\n",
       "  'east': False,\n",
       "  'pinup': False,\n",
       "  'filmy': False,\n",
       "  'podrace': False,\n",
       "  'unmatched': False,\n",
       "  ...},\n",
       " 'neg')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[0] # list(dictionary, category) and in category we have pos or neg\n",
    "               # in dictionary we have 3000 features i.e. words in a document that are most common \n",
    "               # if the word is their in the document and it is also common then we will either True / False\n",
    "               # You can see below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier with NLTK\n",
    "\n",
    "The algorithm that we're going to use first is the Naive Bayes classifier. This is a pretty popular algorithm used in text classification. You could train and test on the same dataset, but this would present you with some serious bias issues, so you should never train and test against the exact same data. \n",
    "\n",
    "Since we've shuffled our data set, **we'll assign the first 1,900 shuffled reviews, consisting of both positive and negative reviews, as the training set. Then, we can test against the last 100 to see how accurate we are.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set that we'll train our classifier with\n",
    "training_set = featuresets[:1900]\n",
    "\n",
    "# set that we'll test against.\n",
    "testing_set = featuresets[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 74.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "# In case you missed it, the reason why we can \"test\" the data is because we still have the correct answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                seamless = True              pos : neg    =      9.6 : 1.0\n",
      "                    scum = True              pos : neg    =      8.3 : 1.0\n",
      "                 layered = True              pos : neg    =      7.6 : 1.0\n",
      "                angelina = True              neg : pos    =      7.1 : 1.0\n",
      "                  suvari = True              neg : pos    =      7.1 : 1.0\n",
      "                  turkey = True              neg : pos    =      6.6 : 1.0\n",
      "                  venice = True              pos : neg    =      6.3 : 1.0\n",
      "            breathtaking = True              pos : neg    =      6.0 : 1.0\n",
      "             uninvolving = True              neg : pos    =      5.9 : 1.0\n",
      "             mesmerizing = True              pos : neg    =      5.8 : 1.0\n",
      "                 matches = True              pos : neg    =      5.8 : 1.0\n",
      "                gayheart = True              neg : pos    =      5.7 : 1.0\n",
      "                   vapid = True              neg : pos    =      5.7 : 1.0\n",
      "              scratching = True              neg : pos    =      5.7 : 1.0\n",
      "                expertly = True              pos : neg    =      5.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# most valuable words are when it comes to positive or negative reviews\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This tells you is the ratio of occurences in negative to positive, or visa versa, for every word.**\n",
    "\n",
    "**So here, we can see that the term \"fascination\" appears 11.0 more times as often in positive reviews as it does in negative reviews.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Classifiers with NLTK\n",
    "\n",
    "We use the Pickle module to go ahead and serialize our classifier object, so that all we need to do is load that \n",
    "file in real quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This opens up a pickle file, preparing to write in bytes some data.      \n",
    "Then, we use pickle.dump() to dump the data. The first parameter to pickle.dump() is what are you dumping, the second parameter is where are you dumping it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The .pickle file is a serialized object, all we need to do now is read it into memory, which will be about as quick as reading any other ordinary file.**\n",
    "\n",
    "**Here, we do a very similar process. We open the file to read as bytes. Then, we use pickle.load() to load the file, and we save the data to the classifier variable. Then we close the file, and that is that**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_f = open(\"naivebayes.pickle\", \"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Sklearn with NLTK\n",
    "\n",
    "Luckily for us, the people behind NLTK forsaw the value of incorporating the sklearn module into the NLTK classifier methodology. As such, they created the SklearnClassifier API of sorts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier      # This SklearnClassifier is a High Level Wrapper\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy percent: 0.7\n",
      "BernoulliNB accuracy percent: 0.75\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MultinomialNB accuracy percent:\",nltk.classify.accuracy(MNB_classifier, testing_set))\n",
    "\n",
    "BNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB accuracy percent:\",nltk.classify.accuracy(BNB_classifier, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 74.0\n",
      "Most Informative Features\n",
      "                seamless = True              pos : neg    =      9.6 : 1.0\n",
      "                    scum = True              pos : neg    =      8.3 : 1.0\n",
      "                 layered = True              pos : neg    =      7.6 : 1.0\n",
      "                angelina = True              neg : pos    =      7.1 : 1.0\n",
      "                  suvari = True              neg : pos    =      7.1 : 1.0\n",
      "                  turkey = True              neg : pos    =      6.6 : 1.0\n",
      "                  venice = True              pos : neg    =      6.3 : 1.0\n",
      "            breathtaking = True              pos : neg    =      6.0 : 1.0\n",
      "             uninvolving = True              neg : pos    =      5.9 : 1.0\n",
      "             mesmerizing = True              pos : neg    =      5.8 : 1.0\n",
      "                 matches = True              pos : neg    =      5.8 : 1.0\n",
      "                gayheart = True              neg : pos    =      5.7 : 1.0\n",
      "                   vapid = True              neg : pos    =      5.7 : 1.0\n",
      "              scratching = True              neg : pos    =      5.7 : 1.0\n",
      "                expertly = True              pos : neg    =      5.6 : 1.0\n",
      "MNB_classifier accuracy percent: 70.0\n",
      "BernoulliNB_classifier accuracy percent: 75.0\n",
      "LogisticRegression_classifier accuracy percent: 72.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sparsh/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 66.0\n",
      "SVC_classifier accuracy percent: 46.0\n",
      "LinearSVC_classifier accuracy percent: 69.0\n",
      "NuSVC_classifier accuracy percent: 71.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Algorithms with NLTK\n",
    "\n",
    "Combining classifier algorithms is is a common technique, done by creating a sort of voting system, where each algorithm gets one vote, and the classification that has the votes votes is the chosen one.\n",
    "\n",
    "To do this, we want our new classifier to act like a typical NLTK classifier, with all of the methods. Simple enough, using object oriented programming, we can just be sure to inherit from the NLTK classifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're calling our class the VoteClassifier, and we're inheriting from NLTK's ClassifierI. Next, we're assigning the list of classifiers that are passed to our class to self._classifiers.\n",
    "\n",
    "Easy enough, all we're doing here is iterating through our list of classifier objects. Then, for each one, we ask it to classify based on the features. The classification is being treated as a vote. After we are done iterating, we then return the mode(votes), which is just returning the most popular vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):    # Through this we can give a list of classifiers\n",
    "        self._classifiers = classifiers\n",
    "    \n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "    \n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voted_classifier accuracy percent: 74.0\n",
      "Classification: neg Confidence %: 100.0\n",
      "Classification: pos Confidence %: 100.0\n",
      "Classification: neg Confidence %: 85.71428571428571\n",
      "Classification: neg Confidence %: 85.71428571428571\n",
      "Classification: neg Confidence %: 100.0\n",
      "Classification: neg Confidence %: 57.14285714285714\n"
     ]
    }
   ],
   "source": [
    "voted_classifier = VoteClassifier(classifier,\n",
    "                                  NuSVC_classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  SGDClassifier_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)\n",
    "\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[0][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[0][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[1][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[1][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[2][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[2][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[3][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[3][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[4][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[4][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[5][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[5][0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating bias with NLTK\n",
    "\n",
    "The most major issue is that we have a fairly biased algorithm. You can test this yourself by commenting-out the shuffling of the documents, then training against the first 1900, and leaving the last 100 (all positive) reviews. Test, and you will find you have very poor accuracy.\n",
    "\n",
    "Conversely, you can test against the first 100 data sets, all negative, and train against the following 1900. You will find very high accuracy here. This is a bad sign.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Training Data for sentiment analysis with NLTK\n",
    "\n",
    "So now it is time to train on a new data set. Our goal is to do Twitter sentiment, so we're hoping for a data set that is a bit shorter per positive and negative statement. It just so happens that I have a data set of 5300+ positive and 5300+ negative movie reviews, which are much shorter.\n",
    "\n",
    "We need a new methodology for creating our \"documents\" variable, and then we also need a new way to create the \"all_words\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 4645: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-d3e3c902b19b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mshort_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positive.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# This is not working find another method to open.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mshort_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf3 in position 4645: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "        \n",
    "short_pos = open(\"positive.txt\").read()           # This is not working find another method to open.\n",
    "short_neg = open(\"negative.txt\").read()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for r in short_pos.split('\\n'):\n",
    "    documents.append( (r, \"pos\") )\n",
    "\n",
    "for r in short_neg.split('\\n'):\n",
    "    documents.append( (r, \"neg\") )\n",
    "\n",
    "\n",
    "all_words = []\n",
    "\n",
    "short_pos_words = word_tokenize(short_pos)\n",
    "short_neg_words = word_tokenize(short_neg)\n",
    "\n",
    "for w in short_pos_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "for w in short_neg_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "# positive data example:      \n",
    "training_set = featuresets[:10000]\n",
    "testing_set =  featuresets[10000:]\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "##SVC_classifier = SklearnClassifier(SVC())\n",
    "##SVC_classifier.train(training_set)\n",
    "##print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  NuSVC_classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-fe7a57a9b753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpositive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'positive' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
